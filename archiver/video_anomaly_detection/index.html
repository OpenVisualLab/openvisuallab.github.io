<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.9" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.38" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://openvisuallab.github.io/archiver/video_anomaly_detection/"><meta property="og:site_name" content="OpenVisualLab"><meta property="og:title" content="Overview"><meta property="og:description" content="➢ 认识异常检测 ■ 什么是视频异常检测？ 视频异常检测（Video Anomaly Detection, VAD）是指在视频序列中自动检测和定位异常事件或行为的任务。异常是指与正常模式显著不同的事件，如交通事故、犯罪行为等。VAD 在安全监控、智能交通系统和公共安全等领域中有广泛的应用。 1. 简单介绍（从异常行为检测到视频异常行为检测） [1] 异..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2024-11-04T14:23:16.000Z"><meta property="article:author" content="Mo Meng Jingcheng (莫梦竟成); Zheng JianKang (郑健康)"><meta property="article:modified_time" content="2024-11-04T14:23:16.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Overview","image":[""],"dateModified":"2024-11-04T14:23:16.000Z","author":[{"@type":"Person","name":"Mo Meng Jingcheng (莫梦竟成); Zheng JianKang (郑健康)"}]}</script><title>Overview | OpenVisualLab</title><meta name="description" content="➢ 认识异常检测 ■ 什么是视频异常检测？ 视频异常检测（Video Anomaly Detection, VAD）是指在视频序列中自动检测和定位异常事件或行为的任务。异常是指与正常模式显著不同的事件，如交通事故、犯罪行为等。VAD 在安全监控、智能交通系统和公共安全等领域中有广泛的应用。 1. 简单介绍（从异常行为检测到视频异常行为检测） [1] 异...">
    <link rel="preload" href="/assets/style-R-pfGLjL.css" as="style"><link rel="stylesheet" href="/assets/style-R-pfGLjL.css">
    <link rel="modulepreload" href="/assets/app-MVVvdJ3R.js"><link rel="modulepreload" href="/assets/index.html-CA5LAYKR.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-DhF5XMNs.js" as="script"><link rel="prefetch" href="/assets/intro.html-nLyQ5AS4.js" as="script"><link rel="prefetch" href="/assets/for_dagr.html-M-w4fSxj.js" as="script"><link rel="prefetch" href="/assets/index.html-Jc7HA-OR.js" as="script"><link rel="prefetch" href="/assets/index.html-QCpKHLPX.js" as="script"><link rel="prefetch" href="/assets/anno.html-ylvAc5rx.js" as="script"><link rel="prefetch" href="/assets/index.html-COeG2moV.js" as="script"><link rel="prefetch" href="/assets/index.html-D_N56fRE.js" as="script"><link rel="prefetch" href="/assets/index.html-B3ymDGcz.js" as="script"><link rel="prefetch" href="/assets/index.html-ByIYHWnY.js" as="script"><link rel="prefetch" href="/assets/LLM4AD.html-BgUES0vk.js" as="script"><link rel="prefetch" href="/assets/UVAD.html-CPqQnaGS.js" as="script"><link rel="prefetch" href="/assets/index.html-CoNnnw8_.js" as="script"><link rel="prefetch" href="/assets/241028_CLOVER_NeurIPS24_qyj.html-CY1LT5hS.js" as="script"><link rel="prefetch" href="/assets/241104_DriveLM_ECCV24_Oral_wjx.html-CC2ESqyA.js" as="script"><link rel="prefetch" href="/assets/241111_Vista_NeruIPS24_zmj.html-BcYXGuHo.js" as="script"><link rel="prefetch" href="/assets/241118_SparseDrive_arXiv24_ys.html-DotWl0gZ.js" as="script"><link rel="prefetch" href="/assets/241202_DeeR-VLA_NeurIPS24_ysd.html-DYAcqYsa.js" as="script"><link rel="prefetch" href="/assets/241216_Causal-CoG_CVPR24_wjx.html-Cc2w-UEr.js" as="script"><link rel="prefetch" href="/assets/index.html-D88g5Gvb.js" as="script"><link rel="prefetch" href="/assets/241216_Causal-CoG_CVPR24_wjx.html-B9PTs2EH.js" as="script"><link rel="prefetch" href="/assets/241230_Drive_WM_CVPR24_zmz.html-CdIo7tel.js" as="script"><link rel="prefetch" href="/assets/250106_ECoT_CoRL24_ysd.html-Cz9JmBn6.js" as="script"><link rel="prefetch" href="/assets/404.html-BQwHcwGG.js" as="script"><link rel="prefetch" href="/assets/index.html-Dp1iSqdS.js" as="script"><link rel="prefetch" href="/assets/index.html-GDpcEZZn.js" as="script"><link rel="prefetch" href="/assets/index.html-CJwAUPuN.js" as="script"><link rel="prefetch" href="/assets/index.html-CL8SoJMM.js" as="script"><link rel="prefetch" href="/assets/index.html-C7CzTX7M.js" as="script"><link rel="prefetch" href="/assets/index.html-BAlxhZpO.js" as="script"><link rel="prefetch" href="/assets/index.html-BreRFoC8.js" as="script"><link rel="prefetch" href="/assets/index.html-DNOzzESm.js" as="script"><link rel="prefetch" href="/assets/index.html-BCEFHzB9.js" as="script"><link rel="prefetch" href="/assets/index.html-BGaUaRYj.js" as="script"><link rel="prefetch" href="/assets/index.html-ZVnQLIjj.js" as="script"><link rel="prefetch" href="/assets/index.html-BWDm8Xy3.js" as="script"><link rel="prefetch" href="/assets/giscus--_FS5kYt.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo" src="/assets/icon/logo.webp" alt><!----><span class="vp-site-name hide-in-pad">OpenVisualLab</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link nav-link" href="/polaris/" aria-label="Polaris"><span class="font-icon icon fa-fw fa-sm fas fa-meteor" style=""></span>Polaris<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="Archiver"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-box-archive" style=""></span>Archiver</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>intelligence</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/worldmodel/" aria-label="World Model"><span class="font-icon icon fa-fw fa-sm fas fa-earth-asia" style=""></span>World Model<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/driving_with_language/" aria-label="Autonomous Driving"><span class="font-icon icon fa-fw fa-sm fas fa-car" style=""></span>Autonomous Driving<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/robot_arm/" aria-label="Robotic Arms"><span class="font-icon icon fa-fw fa-sm fas fa-robot" style=""></span>Robotic Arms<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/robot_arm/" aria-label="Foundational Model"><span class="font-icon icon fa-fw fa-sm fas fa-robot" style=""></span>Foundational Model<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>perception</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/object_detection.html" aria-label="Object Detection"><span class="font-icon icon fa-fw fa-sm fas fa-expand" style=""></span>Object Detection<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/road.html" aria-label="Road-scene Anomaly"><span class="font-icon icon fa-fw fa-sm fas fa-road" style=""></span>Road-scene Anomaly<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link active" href="/archiver/video_anomaly_detection/" aria-label="Video Anomaly"><span class="font-icon icon fa-fw fa-sm fas fa-video" style=""></span>Video Anomaly<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/medical/" aria-label="Medical Segmentation"><span class="font-icon icon fa-fw fa-sm fas fa-brain" style=""></span>Medical Segmentation<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/archiver/event_camera/" aria-label="Event Camera"><span class="font-icon icon fa-fw fa-sm fas fa-camera-rotate" style=""></span>Event Camera<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="Browser"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Browser</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>papers</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/browser/epoch_one_24_1028_1202/" aria-label="epoch_one"><span class="font-icon icon fa-fw fa-sm fas fa-expand" style=""></span>epoch_one<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>dataset</span></h4><ul class="dropdown-subitem-wrapper"></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>learning</span></h4><ul class="dropdown-subitem-wrapper"></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="Coooder"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-code" style=""></span>Coooder</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>Ubuntu</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/docs/coooder/ubuntu/" aria-label="ubuntu"><span class="font-icon icon fa-fw fa-sm fas fa-computer" style=""></span>ubuntu<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/docs/coooder/ubuntu/process/docker.html" aria-label="docker"><span class="font-icon icon fa-fw fa-sm fas fa-shapes" style=""></span>docker<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>MacOS</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/docs/coooder/mac/" aria-label="Almost"><span class="font-icon icon fa-fw fa-sm fas fa-rainbow" style=""></span>Almost<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="Discover"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-fire" style=""></span>Discover</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="route-link nav-link" href="/discover/uncover/" aria-label="overview"><span class="font-icon icon fa-fw fa-sm fas fa-eye" style=""></span>overview<!----></a></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>Big Model</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/discover/uncover/CoT.html" aria-label="ICL/CoT/GoT"><span class="font-icon icon fa-fw fa-sm fas fa-code-branch" style=""></span>ICL/CoT/GoT<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/discover/uncover/2.html" aria-label="Awesome Model"><span class="font-icon icon fa-fw fa-sm fas fa-cable-car" style=""></span>Awesome Model<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>Handy Kit</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a class="route-link nav-link" href="/discover/uncover/open-world/1.html" aria-label="Invoke"><span class="font-icon icon fa-fw fa-sm fas fa-robot" style=""></span>Invoke<!----></a></li><li class="dropdown-subitem"><a class="route-link nav-link" href="/discover/uncover/open-world/2.html" aria-label="Deployment"><span class="font-icon icon fa-fw fa-sm fas fa-cube" style=""></span>Deployment<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a href="http://10.16.38.164/" rel="noopener noreferrer" target="_blank" aria-label="Visual Lab" class="nav-link"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span>Visual Lab<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/OpenVisualLab/openvisuallab.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/" aria-label="Home"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><span class="font-icon icon fa-fw fa-sm fas fa-meteor" style=""></span><span class="vp-sidebar-title">Nav</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Archiver</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Driving with Language</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Event Camera</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Medical Image Segmentation</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Video Anomaly Detection</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link nav-link active vp-sidebar-link vp-sidebar-page active" href="/archiver/video_anomaly_detection/" aria-label="Overview"><!---->Overview<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/archiver/video_anomaly_detection/LLM4AD.html" aria-label="LLM4Anomaly"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>LLM4Anomaly<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/archiver/video_anomaly_detection/UVAD.html" aria-label="Video Anomaly"><!---->Video Anomaly<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">World Model</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">机械臂</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Coooder</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">MindfulPaper</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/intro.html" aria-label="Portfolio Home"><span class="font-icon icon fa-fw fa-sm fas fa-circle-info" style=""></span>Portfolio Home<!----></a></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Overview</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Mo Meng Jingcheng (莫梦竟成); Zheng JianKang (郑健康)</span></span><span property="author" content="Mo Meng Jingcheng (莫梦竟成); Zheng JianKang (郑健康)"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-10-20T13:42:34.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 9 min</span><meta property="timeRequired" content="PT9M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!--[--><!----><!--]--><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#➢-认识异常检测">➢ 认识异常检测</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-什么是视频异常检测">■ 什么是视频异常检测？</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-视频异常检测的挑战">■ 视频异常检测的挑战</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-视频异常检测方法分类">■ 视频异常检测方法分类</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-经典数据集">■ 经典数据集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-评价指标">■ 评价指标</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#➢-优秀团队-学术大佬">➢ 优秀团队 / 学术大佬</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-高盛华-上海科技大学-视觉与数据智能中心">■ 高盛华 - 上海科技大学（视觉与数据智能中心）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-radu-ionescu-securifai-university-of-bucharest">■ Radu Ionescu - SecurifAI/University of Bucharest</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#➢-经典论文推荐-加-👍">➢ 经典论文推荐（加“👍”）</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-unsupervised-vad">■ Unsupervised VAD</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-weakly-supervised-vad">■ Weakly Supervised VAD</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-based-on-large-model">■ Based on Large Model</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#➢-经典项目">➢ 经典项目</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#➢-发现的新的有意思的研究方向-→-explainable-anomaly-detection-ead-可解释性异常检测">➢ 发现的新的有意思的研究方向 → Explainable Anomaly Detection (EAD) 可解释性异常检测</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-定义">■ 定义</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#■-相关工作">■ 相关工作</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h2 id="➢-认识异常检测" tabindex="-1"><a class="header-anchor" href="#➢-认识异常检测"><span>➢ 认识异常检测</span></a></h2><h3 id="■-什么是视频异常检测" tabindex="-1"><a class="header-anchor" href="#■-什么是视频异常检测"><span>■ 什么是视频异常检测？</span></a></h3><p>视频异常检测（Video Anomaly Detection, VAD）是指在视频序列中自动检测和定位异常事件或行为的任务。异常是指与正常模式显著不同的事件，如交通事故、犯罪行为等。VAD 在安全监控、智能交通系统和公共安全等领域中有广泛的应用。</p><h4 id="_1-简单介绍-从异常行为检测到视频异常行为检测" tabindex="-1"><a class="header-anchor" href="#_1-简单介绍-从异常行为检测到视频异常行为检测"><span>1. 简单介绍（从异常行为检测到视频异常行为检测）</span></a></h4><ul><li>[1] 异常行为检测简介：<a href="https://mp.weixin.qq.com/s/UmT0DjFqRPsjv2m28ySvdw" target="_blank" rel="noopener noreferrer"><code>link</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[2] 基于深度学习的异常行为检测介绍：<a href="https://mp.weixin.qq.com/s/Aghbz4m1eWFCNGgEy8q6Cg" target="_blank" rel="noopener noreferrer"><code>link</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[3] 研究现状：<a href="https://mp.weixin.qq.com/s/MwpELRlC1cuDgqn4staAzA" target="_blank" rel="noopener noreferrer"><code>link</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[4] 视频异常行为检测简介：<a href="https://mp.weixin.qq.com/s/i3Xw2-ivARnF7rBSFtxugw" target="_blank" rel="noopener noreferrer"><code>link</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><h4 id="_2-论文综述" tabindex="-1"><a class="header-anchor" href="#_2-论文综述"><span>2. 论文综述</span></a></h4><ul><li>[1] 邬开俊等. 视频异常检测技术研究进展 [J]. 计算机科学与探索, 2022。</li><li>[2] Bharathkumar Ramachandra et al. A survey of single-scene video anomaly detection (TPAMI 2020)。</li></ul><h3 id="■-视频异常检测的挑战" tabindex="-1"><a class="header-anchor" href="#■-视频异常检测的挑战"><span>■ 视频异常检测的挑战</span></a></h3><ul><li><strong>异常定义的模糊性</strong>：异常事件的定义通常是主观的，具有多样性，导致检测难度较大。</li><li><strong>数据不平衡</strong>：正常事件在视频数据中远多于异常事件，这导致训练过程中的数据不平衡问题。</li><li><strong>实时性要求</strong>：在实际应用中，需要实时检测异常以便及时响应。</li><li><strong>场景多样性</strong>：视频场景和拍摄角度的多样性增加了检测难度。</li></ul><h3 id="■-视频异常检测方法分类" tabindex="-1"><a class="header-anchor" href="#■-视频异常检测方法分类"><span>■ 视频异常检测方法分类</span></a></h3><h4 id="_1-无监督方法" tabindex="-1"><a class="header-anchor" href="#_1-无监督方法"><span>1. 无监督方法</span></a></h4><p>无监督方法不需要标签数据，仅依赖正常样本来学习正常行为的模式，通过检测偏离这些模式的行为来识别异常。</p><ul><li><strong>自编码器</strong>：通过重建输入视频帧，若重建误差较高则认为是异常。</li><li><strong>记忆增强网络</strong>：通过将正常行为存储在记忆模块中，当新输入不匹配这些记忆时，检测为异常。</li></ul><h4 id="_2-弱监督方法" tabindex="-1"><a class="header-anchor" href="#_2-弱监督方法"><span>2. 弱监督方法</span></a></h4><p>弱监督方法使用视频级别的标签进行训练，不需要逐帧标注。</p><ul><li><strong>多实例学习</strong>：将视频看作由多个实例组成的包，通过学习视频中正常和异常实例的差异来检测异常。</li><li><strong>对比学习</strong>：通过比较正常和异常数据，学习到区分特征。</li></ul><h3 id="■-经典数据集" tabindex="-1"><a class="header-anchor" href="#■-经典数据集"><span>■ 经典数据集</span></a></h3><h4 id="_1-无监督数据集" tabindex="-1"><a class="header-anchor" href="#_1-无监督数据集"><span>1. 无监督数据集</span></a></h4><ul><li><strong>UCSD Pedestrian</strong>：主要用于行人行为分析，包含行人通道中的异常事件，如骑自行车、滑板等。此数据集通常用于无监督异常检测。</li><li><strong>ShanghaiTech</strong>：较大规模的数据集，包含校园监控视频，涵盖多种异常行为，适用于无监督方法。</li><li><strong>Avenue</strong>：以校园场景为背景，涵盖诸如突然跑步、丢弃物品等异常行为。此数据集适用于无监督异常检测方法。</li></ul><h4 id="_2-弱监督数据集" tabindex="-1"><a class="header-anchor" href="#_2-弱监督数据集"><span>2. 弱监督数据集</span></a></h4><ul><li><strong>UCF-Crime</strong>：一个用于弱监督视频异常检测的大规模数据集，涵盖不同场景下的犯罪行为，如偷窃、打架等。视频级标注用于训练和评估模型。</li><li><strong>XD-Violence</strong>：包含各种暴力事件的视频数据集，常用于弱监督方法，帮助模型学习区分正常与异常行为。</li><li><strong>UCFCrime2Local</strong>：UCF-Crime 的子集，包含空间标注，用于在弱监督条件下进行异常事件的精确定位。</li></ul><h3 id="■-评价指标" tabindex="-1"><a class="header-anchor" href="#■-评价指标"><span>■ 评价指标</span></a></h3><h4 id="_1-auc-曲线下面积" tabindex="-1"><a class="header-anchor" href="#_1-auc-曲线下面积"><span>1. AUC（曲线下面积）</span></a></h4><ul><li><strong>定义</strong>：AUC（Area Under the Curve）指的是 ROC 曲线（接收者操作特征曲线）下的面积。ROC 曲线描绘了模型在不同阈值下的假阳性率与真阳性率的关系。</li><li><strong>用途</strong>：用于衡量分类模型在不同阈值下的整体性能。AUC 值越接近 1，模型的区分能力越强。</li><li><strong>优点</strong>：在衡量模型的总体表现时，AUC 可以帮助了解模型的稳定性和判别能力，不依赖于具体的阈值。</li></ul><h4 id="_2-eer-等错误率" tabindex="-1"><a class="header-anchor" href="#_2-eer-等错误率"><span>2. EER（等错误率）</span></a></h4><ul><li><strong>定义</strong>：EER（Equal Error Rate）是指假阳性率（False Positive Rate, FPR）和假阴性率（False Negative Rate, FNR）相等时的错误率。</li><li><strong>用途</strong>：常用于验证模型性能的一个稳定点，尤其是在需要权衡假阳性和假阴性影响时。</li><li><strong>优点</strong>：EER 可以为不同阈值下的平衡性能提供直接的比较，适用于二分类问题中权重相当的应用场景。</li></ul><h4 id="_3-f1-score" tabindex="-1"><a class="header-anchor" href="#_3-f1-score"><span>3. F1-score</span></a></h4><ul><li><strong>定义</strong>：F1-score 是精确率（Precision）和召回率（Recall）的调和平均数，公式为：<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mrow><mtext>Precision</mtext><mo>×</mo><mtext>Recall</mtext></mrow><mrow><mtext>Precision</mtext><mo>+</mo><mtext>Recall</mtext></mrow></mfrac></mrow><annotation encoding="application/x-tex"> F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.1408em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">Recall</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">Recall</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><strong>用途</strong>：用于在分类问题中权衡模型的精确率和召回率，特别是在类分布不平衡时尤为有效。</li><li><strong>优点</strong>：F1-score 平衡考虑了精确率和召回率，适合评估那些对假阳性和假阴性影响敏感的模型。</li><li><strong>应用场景</strong>：适用于异常检测中对误报和漏报都有较高要求的场合。</li></ul><h4 id="_4-precision-精确率" tabindex="-1"><a class="header-anchor" href="#_4-precision-精确率"><span>4. Precision（精确率）</span></a></h4><ul><li><strong>定义</strong>：精确率是指模型预测为正样本的实例中实际为正样本的比例。公式为：<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Precision</mtext><mo>=</mo><mfrac><mtext>TP</mtext><mrow><mtext>TP</mtext><mo>+</mo><mtext>FP</mtext></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">TP</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">FP</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><strong>用途</strong>：衡量模型预测结果的准确性，适用于对假阳性率较敏感的应用。</li></ul><h4 id="_5-recall-召回率" tabindex="-1"><a class="header-anchor" href="#_5-recall-召回率"><span>5. Recall（召回率）</span></a></h4><ul><li><strong>定义</strong>：召回率是指实际为正样本的实例中被模型正确预测为正样本的比例。公式为：<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Recall</mtext><mo>=</mo><mfrac><mtext>TP</mtext><mrow><mtext>TP</mtext><mo>+</mo><mtext>FN</mtext></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">Recall</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">TP</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">FN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><strong>用途</strong>：评估模型对正样本的检测能力，适用于对假阴性率较敏感的场景。</li></ul><p>每个指标在不同的应用场景中具有不同的重要性。例如，在安全监控中，可能更关注召回率，以确保尽可能少的异常被漏检；而在高误报成本的场景下，精确率则更为重要。</p><h2 id="➢-优秀团队-学术大佬" tabindex="-1"><a class="header-anchor" href="#➢-优秀团队-学术大佬"><span>➢ 优秀团队 / 学术大佬</span></a></h2><h3 id="■-高盛华-上海科技大学-视觉与数据智能中心" tabindex="-1"><a class="header-anchor" href="#■-高盛华-上海科技大学-视觉与数据智能中心"><span>■ 高盛华 - 上海科技大学（视觉与数据智能中心）</span></a></h3><ul><li>[1] A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework (ICCV 2017) 提出了ShanghaiTech数据集。</li><li>[2] Future Frame Prediction for Anomaly Detection – A New Baseline (CVPR 2018)。</li><li>[3] Future Frame Prediction for Anomaly Detection (TPAMI 2022)。</li></ul><h3 id="■-radu-ionescu-securifai-university-of-bucharest" tabindex="-1"><a class="header-anchor" href="#■-radu-ionescu-securifai-university-of-bucharest"><span>■ Radu Ionescu - SecurifAI/University of Bucharest</span></a></h3><ul><li>[1] Detecting abnormal events in video using Narrowed Normality Clusters (WACV 2019)。</li><li>[2] Object-centric Auto-encoders and Dummy Anomalies for Abnormal Event Detection in Video (CVPR 2019)。</li><li>[3] Anomaly Detection in Video via Self-Supervised and Multi-Task Learning (CVPR 2021)。</li><li>[4] A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video (TPAMI 2021)。</li><li>[5] UBnormal New Benchmark for Supervised Open-Set Video Anomaly Detection (CVPR 2022)。</li><li>[6] Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection (CVPR 2022)。</li></ul><h2 id="➢-经典论文推荐-加-👍" tabindex="-1"><a class="header-anchor" href="#➢-经典论文推荐-加-👍"><span>➢ 经典论文推荐（加“👍”）</span></a></h2><h3 id="■-unsupervised-vad" tabindex="-1"><a class="header-anchor" href="#■-unsupervised-vad"><span>■ Unsupervised VAD</span></a></h3><ul><li><p><strong>Conference Papers</strong></p><ul><li>[1] Learning Temporal Regularity in Video Sequences (CVPR 2016)。</li><li>[2] 👍 Future Frame Prediction for Anomaly Detection – A New Baseline (CVPR 2018)。</li><li>[3] 👍 Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection (ICCV 2019) → 首次在视频异常检测中使用记忆模块。</li><li>[4] 👍 Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection (CVPR 2019) → 首次结合对象检测和VAD以实现对象级异常检测。</li><li>[5] AnoPCN: Video Anomaly Detection via Deep Predictive Coding Network (ACM MM 2019) → 首个混合模型。</li><li>[6] 👍 Learning Memory-guided Normality for Anomaly Detection (CVPR 2020) → 基于MemAE。</li><li>[7] Cluster Attention Contrast for Video Anomaly Detection (ACM MM 2020) → 首次应用对比学习。</li><li>[8] 👍 Anomaly Detection in Video via Self-Supervised and Multi-Task Learning (CVPR 2021) → 对象级。</li><li>[9] 👍 A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction (ICCV 2021) → 混合模型。</li><li>[10] Anomaly Detection in Video Sequence with Appearance-Motion Correspondence (ICCV 2019) → 双流网络。</li><li>[11] Video Anomaly Detection and Localization via Gaussian Mixture Fully Convolutional Variational Autoencoder → 双流网络。</li><li>[12] Self-supervised Sparse Representation for Video Anomaly Detection (ECCV 2022) → 首次尝试解决无监督和弱监督VAD。</li><li>[13] Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles (ECCV 2022)。</li></ul></li><li><p><strong>Journal Papers</strong></p><ul><li>[1] Video Anomaly Detection with Sparse Coding Inspired Deep Neural Networks (TPAMI 2021)。</li><li>[2] A Background-Agnostic Framework With Adversarial Training for Abnormal Event Detection in Video (TPAMI 2022)。</li><li>[3] Influence-Aware Attention Networks for Anomaly Detection in Surveillance Videos (TCSVT 2022)。</li><li>[4] Bidirectional Spatio-Temporal Feature Learning With Multiscale Evaluation for Video Anomaly Detection (TCSVT 2022)。</li><li>[5] Anomaly Detection With Bidirectional Consistency in Videos (TNNLS 2022)。</li><li>[6] Variational Abnormal Behavior Detection With Motion Consistency (TIP 2022)。</li><li>[7] DoTA: Unsupervised Detection of Traffic Anomaly in Driving Videos (TPAMI 2023)。</li><li>[8] A Hierarchical Spatio-Temporal Graph Convolutional Neural Network for Anomaly Detection in Videos (TCSVT 2023)。</li><li>[9] Learnable Locality-Sensitive Hashing for Video Anomaly Detection (TCSVT 2023)。</li><li>[10] A Kalman Variational Autoencoder Model Assisted by Odometric Clustering for Video Frame Prediction and Anomaly Detection (TIP 2023)。</li><li>[11] Abnormal Event Detection and Localization via Adversarial Event Prediction (TNNLS 2023)。</li></ul></li></ul><h3 id="■-weakly-supervised-vad" tabindex="-1"><a class="header-anchor" href="#■-weakly-supervised-vad"><span>■ Weakly Supervised VAD</span></a></h3><ul><li>[1] 👍 Real-world Anomaly Detection in Surveillance Videos (CVPR 2018)。<a href="http://crcv.ucf.edu/projects/real-world/" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[2] Weakly Supervised Video Anomaly Detection via Center-Guided Discriminative Learning (ICME 2020)。</li><li>[3] Graph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection (CVPR 2019)。<a href="https://github.com/jx-zhong-for-academic-purpose/GCN-Anomaly-Detection" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[4] Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision (ECCV 2020)。<a href="https://roc-ng.github.io/XD-Violence/" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[5] CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy Suppression for Anomalous Event Detection (ECCV 2020)。<a href="https://github.com/xaggi/claws_eccv" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[6] Localizing Anomalies From Weakly-Labeled Videos (TIP 2021)。<a href="https://github.com/ktr-hubrt/WSAL" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[7] Learning Normal Dynamics in Videos with Meta Prototype Network (CVPR 2021)。<a href="https://github.com/ktr-hubrt/MPN" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[8] Weakly-Supervised Spatio-Temporal Anomaly Detection in Surveillance Video (IJCAI 2021)。</li><li>[9] Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning (ICCV 2021)。<a href="https://github.com/tianyu0207/RTFM" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[10] MIST: Multiple Instance Self-Training Framework for Video Anomaly Detection (CVPR 2021)。<a href="https://github.com/fjchange/MIST_VAD" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[11] Self-Training Multi-Sequence Learning with Transformer for Weakly Supervised Video Anomaly Detection (AAAI 2022)。<a href="https://github.com/LiShuo1001/MSL" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>(only readme)</li><li>[12] Exploiting Completeness and Uncertainty of Pseudo Labels for Weakly Supervised Video Anomaly Detection (CVPR 2022)。<a href="https://github.com/ArielZc/CU-Net" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[13] Modality-Aware Contrastive Instance Learning with Self-Distillation for Weakly-Supervised Audio-Visual Violence Detection (ACM MM 2022)。<a href="https://github.com/JustinYuu/MACIL_SD" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[14] Decouple and Resolve: Transformer-Based Models for Online Anomaly Detection From Weakly Labeled Videos (TIFS 2023)。</li><li>[15] Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection (AAAI 2023)。<a href="https://github.com/henrryzh1/UR-DMU" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[16] TEVAD: Improved video anomaly detection with captions (CVPR 2023)。<a href="https://github.com/coranholmes/TEVAD" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[17] Look Around for Anomalies: Weakly-supervised Anomaly Detection via Context-Motion Relational Learning (CVPR 2023)。</li><li>[18] Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly Detection (CVPR 2023)。<a href="https://github.com/ktr-hubrt/UMIL" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[19] Hierarchical Semantic Contrast for Scene-aware Video Anomaly Detection (CVPR 2023)。<a href="https://github.com/shengyangsun/HSC_VAD" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[20] MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection (AAAI 2023)。</li><li>[21] Dynamic Erasing Network Based on Multi-Scale Temporal Features for Weakly Supervised Video Anomaly Detection (ArXiv 2023)。<a href="https://github.com/ArielZc/DE-Net" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[22] Text Prompt with Normality Guidance for Weakly Supervised Video Anomaly Detection (CVPR 2024)。</li><li>[23] Prompt-Enhanced Multiple Instance Learning for Weakly Supervised Video Anomaly Detection (CVPR 2024)。<a href="https://github.com/Junxi-Chen/PE-MIL" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><h3 id="■-based-on-large-model" tabindex="-1"><a class="header-anchor" href="#■-based-on-large-model"><span>■ Based on Large Model</span></a></h3><ul><li>[1] 👍 Harnessing Large Language Models for Training-free Video Anomaly Detection (CVPR 2024)。<a href="https://lucazanella.github.io/lavad/" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[2] Open-Vocabulary Video Anomaly Detection (CVPR 2024)。</li><li>[3] 👍 Uncovering What, Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly (CVPR 2024)。<a href="https://github.com/fesvhtr/CUVA" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[4] 👍 HAWK: Learning to Understand Open-World Video Anomalies (NeurIPS 2024)。<a href="https://github.com/jqtangust/hawk" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[5] Video Anomaly Detection and Explanation via Large Language Models (ArXiv 2024)。<a href="https://github.com/ktr-hubrt/VAD-LLaMA" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[6] VANE-Bench: Video Anomaly Evaluation Benchmark for Conversational LMMs (ArXiv 2024)。<a href="https://hananshafi.github.io/vane-benchmark/" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[7] 👍 Holmes-VAD: Towards Unbiased and Explainable Video Anomaly Detection via Multi-modal LLM (ArXiv 2024)。<a href="https://holmesvad.github.io/" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>[8] VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection (AAAI 2023)。<a href="https://github.com/nwpu-zxr/VadCLIP" target="_blank" rel="noopener noreferrer"><code>code</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><h2 id="➢-经典项目" tabindex="-1"><a class="header-anchor" href="#➢-经典项目"><span>➢ 经典项目</span></a></h2><ul><li>○ MNAD → <a href="https://github.com/cvlab-yonsei/MNAD" target="_blank" rel="noopener noreferrer"><code>GitHub</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>，可作为视频异常检测的基准项目。</li></ul><h2 id="➢-发现的新的有意思的研究方向-→-explainable-anomaly-detection-ead-可解释性异常检测" tabindex="-1"><a class="header-anchor" href="#➢-发现的新的有意思的研究方向-→-explainable-anomaly-detection-ead-可解释性异常检测"><span>➢ 发现的新的有意思的研究方向 → Explainable Anomaly Detection (EAD) 可解释性异常检测</span></a></h2><h3 id="■-定义" tabindex="-1"><a class="header-anchor" href="#■-定义"><span>■ 定义</span></a></h3><p>此任务旨在检测视频中的异常事件并自动生成高层次解释。理解异常事件的原因至关重要，因为所需的响应取决于其性质和严重性。</p><h3 id="■-相关工作" tabindex="-1"><a class="header-anchor" href="#■-相关工作"><span>■ 相关工作</span></a></h3><ul><li>[1] Joint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge (ICCV 2017)。</li><li>[2] X-MAN: Explaining multiple sources of anomalies in video (CVPR workshop 2021)。</li><li>[3] Discrete neural representations for explainable anomaly detection (WACV 2022)。</li></ul></div><!--[--><!----><!--]--><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a href="https://github.com/OpenVisualLab/openvisuallab.github.io/edit/main/src/archiver/video_anomaly_detection/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page on GitHub" class="nav-link vp-meta-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last update: </span><!----></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 155338123+lemonzjk@users.noreply.github.com">lemonzjk</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><!----><a class="route-link nav-link next" href="/archiver/video_anomaly_detection/LLM4AD.html" aria-label="LLM4Anomaly"><div class="hint">Next<span class="arrow end"></span></div><div class="link">LLM4Anomaly<span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span></div></a></nav><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">ᕦ(ò_óˇ)ᕤ</div><div class="vp-copyright">Copyright © 2025 Mo Meng Jingcheng (莫梦竟成); Zheng JianKang (郑健康) </div></footer></div><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-MVVvdJ3R.js" defer></script>
  </body>
</html>
