import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r,o as l,c as s,a as n,b as e,d as a,f as t}from"./app-5eVdzkVG.js";const u={},g=t('<h1 id="✧-大模型用于自动驾驶相关文献整理" tabindex="-1"><a class="header-anchor" href="#✧-大模型用于自动驾驶相关文献整理"><span>✧ 大模型用于自动驾驶相关文献整理</span></a></h1><p>谷歌学术检索（标题）：intitle:(autonomous driving OR driving OR self-driving AND LLM OR Large Language Model OR Vision-Language OR Agent OR Multi-Modal) 时间范围：2022年——2025年 <img src="https://github.com/user-attachments/assets/fb23cd81-43b6-4e11-8b68-508d038a9ca6" alt="image" loading="lazy"></p><p>arXiv Xplorer检索(全文)：LLM 、large language models、vision language models、AND autonomous driving 按照相似性排序 时间范围：2022年——2024年 <img src="https://github.com/user-attachments/assets/8a871362-65ab-48ec-80b0-bfc902371201" alt="image" loading="lazy"></p><h2 id="➢综述类-★推荐指数" tabindex="-1"><a class="header-anchor" href="#➢综述类-★推荐指数"><span>➢综述类（★推荐指数）</span></a></h2>',4),h={href:"https://arxiv.org/abs/2311.01043",target:"_blank",rel:"noopener noreferrer"},c={href:"https://github.com/Thinklab-SJTU/Awesome-LLM4AD",target:"_blank",rel:"noopener noreferrer"},d=n("br",null,null,-1),b=n("br",null,null,-1),p=n("br",null,null,-1),m=n("br",null,null,-1),v={href:"https://arxiv.org/abs/2311.12320",target:"_blank",rel:"noopener noreferrer"},L={href:"https://github.com/IrohXu/Awesome-Multimodal-LLM-Autonomous-Driving",target:"_blank",rel:"noopener noreferrer"},_=n("br",null,null,-1),f=n("br",null,null,-1),A=n("br",null,null,-1),y=n("br",null,null,-1),M=n("br",null,null,-1),T=n("br",null,null,-1),D={href:"https://arxiv.org/abs/2409.14165",target:"_blank",rel:"noopener noreferrer"},C=n("br",null,null,-1),S=n("br",null,null,-1),Y=n("br",null,null,-1),I=n("br",null,null,-1),P=n("br",null,null,-1),x=n("br",null,null,-1),R=n("br",null,null,-1),E={href:"https://www.arxiv.org/pdf/2409.10484",target:"_blank",rel:"noopener noreferrer"},k=n("br",null,null,-1),w=n("br",null,null,-1),Z=n("br",null,null,-1),X=n("br",null,null,-1),J=n("br",null,null,-1),W=n("br",null,null,-1),O=n("h2",{id:"➢研究类-★推荐指数",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#➢研究类-★推荐指数"},[n("span",null,"➢研究类（★推荐指数）")])],-1),U={href:"https://arxiv.org/abs/2311.01043",target:"_blank",rel:"noopener noreferrer"},V={href:"https://github.com/Thinklab-SJTU/Awesome-LLM4AD",target:"_blank",rel:"noopener noreferrer"},B=n("br",null,null,-1),N=n("br",null,null,-1),H=n("br",null,null,-1),K=n("br",null,null,-1),z=n("br",null,null,-1),j=n("br",null,null,-1),F=t('<p>Title: Drivegpt4: Interpretable end-to-end autonomous driving via large language model<br><br> Authors: Zhenhua Xu, Yujia Zhang, Enze Xie, Zhen Zhao, Yong Guo, Kwan-Yee K. Wong, Zhenguo Li, Hengshuang Zhao<br> Institution:The University of Hong Kong、Zhejiang University、Huawei Noah’s Ark Lab<br> Year: 2024<br> Publication Title: IEEE Robotics and Automation Letters<br></p><p>Title: Lampilot: An open benchmark dataset for autonomous driving with language model programs<br> Authors: Yunsheng Ma, Can Cui, Xu Cao, Wenqian Ye, Peiran Liu, Juanwu Lu, Amr Abdelraouf, Rohit Gupta, Kyungtae Han, Aniket Bera<br> Institution:Purdue University、University of Illinois Urbana-Champaign、University of Virginia<br> Year: 2024<br> Publication Title: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition<br></p><p>Title: A language agent for autonomous driving<br> Authors: Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, Yue Wang<br> Institution:University of Southern California、Stanford University<br> Year: 2023<br> Publication Title: arXiv preprint arXiv:2311.10813<br></p><p>Title: Vision language models in autonomous driving and intelligent transportation systems<br> Authors: Xingcheng Zhou, Mingyu Liu, Bare Luka Zagar, Ekim Yurtsever, Alois C. Knoll<br> Institution:<br> Year: 2023<br> Publication Title: arXiv preprint arXiv:2310.14414<br></p><p>Title: OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning<br> Authors: Shihao Wang, Zhiding Yu, Xiaohui Jiang, Shiyi Lan, Min Shi, Nadine Chang, Jan Kautz, Ying Li, Jose M. Alvarez<br> Institution:Beijing Inst of Tech、NVIDIA<br> Year: 2024<br> Publication Title: arXiv preprint arXiv:2405.01533<br></p><p>Title: Drive like a human: Rethinking autonomous driving with large language models<br> Authors: Daocheng Fu, Xin Li, Licheng Wen, Min Dou, Pinlong Cai, Botian Shi, Yu Qiao<br> Institution:Shanghai AI Lab<br> Year: 2024<br> Publication Title: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision<br></p><p>Title: DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences<br> Authors: Yidong Huang, Jacob Sansom, Ziqiao Ma, Felix Gervits, Joyce Chai<br> Institution:University of Michigan、Army Research Lab<br> Year: 2024<br> Publication Title: arXiv preprint arXiv:2406.03008<br></p><p>Title: Dilu: A knowledge-driven approach to autonomous driving with large language models<br> Authors: Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao Ma, Pinlong Cai, Min Dou, Botian Shi, Liang He, Yu Qiao<br> Institution:Shanghai Artificial Intelligence Laboratory<br> Year: 2023<br> Publication Title: arXiv preprint arXiv:2309.16292<br></p><p>Title: Editable scene simulation for autonomous driving via collaborative LLM-agents<br> Authors: Yuxi Wei, Zi Wang, Yifan Lu, Chenxin Xu, Changxing Liu, Hao Zhao, Siheng Chen, Yanfeng Wang<br> Institution:Shanghai Jiao Tong University、Shanghai AI Laboratory<br> Year: 2024<br> Publication Title: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition<br></p><p>Title: Drivevlm: The convergence of autonomous driving and large vision-language models<br> Authors: Xiaoyu Tian, Junru Gu, Bailin Li, Yicheng Liu, Chenxu Hu, Yang Wang, Kun Zhan, Peng Jia, Xianpeng Lang, Hang Zhao<br> Institution:IIIS, Tsinghua University、Li Auto<br> Year: 2024<br> Publication Title: arXiv preprint arXiv:2402.12289<br></p><p>Title: Vlaad: Vision and language assistant for autonomous driving<br> Authors: SungYeon Park, MinJae Lee, JiHyuk Kang, Hahyeon Choi, Yoonah Park, Juhwan Cho, Adam Lee, DongKyu Kim<br> Institution:Seoul National University、University of California, Berkeley<br> Year: 2024<br> Publication Title: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision<br></p><p>Title: Asynchronous Large Language Model Enhanced Planner for Autonomous Driving<br> Authors: Yuan Chen, Zi-han Ding, Ziqin Wang, Yan Wang, Lijun Zhang, Si Liu<br> Institution: Beihang University、AIR, Tsinghua University<br> Year: 2024<br> Publication Title: arXiv preprint arXiv:2406.14556<br></p><p>Title: Empowering Autonomous Driving with Large Language Models: A Safety Perspective<br> Authors: Yixuan Wang, Ruochen Jiao, Chengtian Lang, Sinong Simon Zhan, Chao Huang, Zhaoran Wang, Zhuoran Yang, Qi Zhu<br> Institution: Northwestern University<br> Year: 2023<br> Publication Title: Arxiv<br></p><p>Title: A Survey of Large Language Models for Autonomous Driving<br> Authors: Zhenjie Yang, Xiaosong Jia, Hongyang Li, Junchi Yan<br> Institution: Shanghai Jiao Tong University<br> Year: 2023<br> Publication Title: Arxiv<br></p><p>Title: SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving<br> Authors: Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu<br> Institution: Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences<br> Year: 2024<br> Publication Title: Arxiv<br></p><h3 id="llm-and-existing-ad-challenges" tabindex="-1"><a class="header-anchor" href="#llm-and-existing-ad-challenges"><span>LLM and Existing AD Challenges</span></a></h3><p>• Solution Insight A: LLMs have demonstrated significant capability in solving the corresponding challenge, and comprehensive solution based on LLMs can be expected.<br> • Solution Insight B: LLMs have demonstrated capability in solving the corresponding challenge, but the challenge may not be fully solved given current drawbacks of LLMs.<br> • Solution Insight C: LLMs can improve performance in related tasks, but might not be able to solve the key problems within the challenges.<br><img src="https://github.com/user-attachments/assets/db47a40a-fd75-4763-afb2-ae5b87495693" alt="image" loading="lazy"><br> LLMs在AD任务中的表现主要源于以下几个方面：</p><ol><li>Common Sense.</li><li>Reasoning Capability.</li><li>Communication ability.(就是与人类互动交流的能力，一定程度上解决了神经网络作为黑盒模型的问题，可信问题)</li></ol><h2 id="➢-llm-related-ad-datasets" tabindex="-1"><a class="header-anchor" href="#➢-llm-related-ad-datasets"><span>➢ LLM Related AD Datasets.</span></a></h2><p><img src="https://github.com/user-attachments/assets/57c1361f-c8bb-4425-9c01-5ce90edadbb8" alt="image" loading="lazy"> Reason2Drive<br> NuPrompt<br> DriveGPT4<br> LingoQA<br> WEDGE<br> DriveLM-nuScenes<br> DriveLM-Carla<br> NuScenes-QA<br> Rank2Tell<br> LaMPilot<br> MAPLM<br> LMDrive</p>',20);function q(G,Q){const i=r("ExternalLinkIcon");return l(),s("div",null,[g,n("p",null,[e("★★★★ LLM4Drive: A Survey of Large Language Models for Autonomous Driving "),n("a",h,[e("paper"),a(i)]),e(),n("a",c,[e("code"),a(i)]),d,e(" Authors: Zhenjie Yang, Xiaosong Jia, Hongyang Li, Junchi Yan"),b,e(" institution: School of AI and Department of CSE, Shanghai Jiao Tong University, OpenDriveLab"),p,e(" year: 2023"),m,e(" eprint: [v4] Mon, 12 Aug 2024 11:53:28 UTC (538 KB)")]),n("p",null,[e("★★★★★ A Survey on Multimodal Large Language Models for Autonomous Driving "),n("a",v,[e("paper"),a(i)]),e(),n("a",L,[e("code"),a(i)]),e(),_,f,e(" Authors: Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Zhou, Yang and Liang, Kaizhao and Chen, Jintai and Lu, Juanwu and Yang, Zichong and Liao, Kuei-Da and others"),A,e(" institution: Purdue University, West Lafayette, IN, USA; Tencent T Lab, Beijing, China; University of Illinois Urbana-Champaign, Champaign, IL, USA"),y,e(" year: 2024"),M,e(" booktitle: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision")]),n("p",null,[e("★★★★ Will Large Language Models be a Panacea to Autonomous Driving?"),T,e(),n("a",D,[e("paper"),a(i)]),e(),C,S,e(" Authors:Yuxuan Zhu, Shiyi Wang, Wenqing Zhong, Nianchen Shen, Yunqi Li, Siqi Wang, Zhiheng Li, Cathy Wu, Zhengbing He, Li Li "),Y,e(" institution:Department of Automation, Tsinghua University, Beijing, China"),I,e(" year: 2024"),P,e(" eprint:arxiv"),x]),n("p",null,[e("Title: XLM for Autonomous Driving Systems: A Comprehensive Review"),R,e(),n("a",E,[e("paper"),a(i)]),e(),k,w,e(" Authors: Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani"),Z,e(" Institution:Mediterranean Institute of Technology (MedTech), Tunis, Tunisia、"),X,e(" Year: 2024"),J,e(" Publication Title: arXiv preprint arXiv:2409.10484"),W]),O,n("p",null,[e("Title: Driving with llms: Fusing object-level vector modality for explainable autonomous driving "),n("a",U,[e("paper"),a(i)]),e(),n("a",V,[e("code"),a(i)]),B,N,e(" Authors: Chen, Long; Sinavski, Oleg; Hünermann, Jan; Karnsund, Alice; Willmott, Andrew James; Birch, Danny; Maund, Daniel; Shotton, Jamie"),H,e(" Institution: Wayve"),K,e(" Year: 2024 "),z,e(" Publication Title: 2024 IEEE International Conference on Robotics and Automation (ICRA)"),j]),F])}const en=o(u,[["render",q],["__file","index.html.vue"]]),an=JSON.parse('{"path":"/archiver/driving_with_language/","title":"Driving with Language","lang":"en-US","frontmatter":{"author":"Jingxin Wang (王京新)","title":"Driving with Language","description":"✧ 大模型用于自动驾驶相关文献整理 谷歌学术检索（标题）：intitle:(autonomous driving OR driving OR self-driving AND LLM OR Large Language Model OR Vision-Language OR Agent OR Multi-Modal) 时间范围：2022年——2025年...","head":[["meta",{"property":"og:url","content":"https://openvisuallab.github.io/archiver/driving_with_language/"}],["meta",{"property":"og:site_name","content":"OpenVisualLab"}],["meta",{"property":"og:title","content":"Driving with Language"}],["meta",{"property":"og:description","content":"✧ 大模型用于自动驾驶相关文献整理 谷歌学术检索（标题）：intitle:(autonomous driving OR driving OR self-driving AND LLM OR Large Language Model OR Vision-Language OR Agent OR Multi-Modal) 时间范围：2022年——2025年..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://github.com/user-attachments/assets/fb23cd81-43b6-4e11-8b68-508d038a9ca6"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-10-11T02:34:41.000Z"}],["meta",{"property":"article:author","content":"Jingxin Wang (王京新)"}],["meta",{"property":"article:modified_time","content":"2024-10-11T02:34:41.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Driving with Language\\",\\"image\\":[\\"https://github.com/user-attachments/assets/fb23cd81-43b6-4e11-8b68-508d038a9ca6\\",\\"https://github.com/user-attachments/assets/8a871362-65ab-48ec-80b0-bfc902371201\\",\\"https://github.com/user-attachments/assets/db47a40a-fd75-4763-afb2-ae5b87495693\\",\\"https://github.com/user-attachments/assets/57c1361f-c8bb-4425-9c01-5ce90edadbb8\\"],\\"dateModified\\":\\"2024-10-11T02:34:41.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Jingxin Wang (王京新)\\"}]}"]]},"headers":[{"level":2,"title":"➢综述类（★推荐指数）","slug":"➢综述类-★推荐指数","link":"#➢综述类-★推荐指数","children":[]},{"level":2,"title":"➢研究类（★推荐指数）","slug":"➢研究类-★推荐指数","link":"#➢研究类-★推荐指数","children":[{"level":3,"title":"LLM and Existing AD Challenges","slug":"llm-and-existing-ad-challenges","link":"#llm-and-existing-ad-challenges","children":[]}]},{"level":2,"title":"➢ LLM Related AD Datasets.","slug":"➢-llm-related-ad-datasets","link":"#➢-llm-related-ad-datasets","children":[]}],"git":{"createdTime":1726303476000,"updatedTime":1728614081000,"contributors":[{"name":"BigBoom","email":"45707903+BigBoomDream@users.noreply.github.com","commits":3},{"name":"2-mo","email":"1982800736@qq.com","commits":2}]},"readingTime":{"minutes":4.42,"words":1325},"filePathRelative":"archiver/driving_with_language/README.md","localizedDate":"September 14, 2024","excerpt":"\\n<p>谷歌学术检索（标题）：intitle:(autonomous driving OR driving OR self-driving AND LLM OR Large Language Model OR Vision-Language OR Agent OR Multi-Modal)\\n时间范围：2022年——2025年\\n<img src=\\"https://github.com/user-attachments/assets/fb23cd81-43b6-4e11-8b68-508d038a9ca6\\" alt=\\"image\\" loading=\\"lazy\\"></p>\\n<p>arXiv Xplorer检索(全文)：LLM 、large language models、vision language models、AND autonomous driving\\n按照相似性排序\\n时间范围：2022年——2024年\\n<img src=\\"https://github.com/user-attachments/assets/8a871362-65ab-48ec-80b0-bfc902371201\\" alt=\\"image\\" loading=\\"lazy\\"></p>","autoDesc":true}');export{en as comp,an as data};
