import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,o as l,c as s,a as r,b as e,d as t,f as i}from"./app-CKSDceth.js";const p={},h=r("h2",{id:"driving-into-the-future-multiview-visual-forecasting-and-planning-with-world-model-for-autonomous-driving-驶向未来-利用自动驾驶世界模型进行多视图视觉预测和规划",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#driving-into-the-future-multiview-visual-forecasting-and-planning-with-world-model-for-autonomous-driving-驶向未来-利用自动驾驶世界模型进行多视图视觉预测和规划"},[r("span",null,"Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving（驶向未来：利用自动驾驶世界模型进行多视图视觉预测和规划）")])],-1),d={href:"https://robertwyq.github.io/",target:"_blank",rel:"noopener noreferrer"},c={href:"https://jiaweihe.com/",target:"_blank",rel:"noopener noreferrer"},u={href:"https://lue.fan/",target:"_blank",rel:"noopener noreferrer"},g={href:"https://github.com/ZJULiHongxin",target:"_blank",rel:"noopener noreferrer"},_={href:"https://scholar.google.com/citations?user=iLOoUqIAAAAJ",target:"_blank",rel:"noopener noreferrer"},m={href:"https://zhaoxiangzhang.net/",target:"_blank",rel:"noopener noreferrer"},v={href:"https://arxiv.org/abs/2311.17918",target:"_blank",rel:"noopener noreferrer"},f={href:"https://drive-wm.github.io/",target:"_blank",rel:"noopener noreferrer"},b=i('<figure><img src="https://github.com/BraveGroup/Drive-WM/assets/27729041/8418123e-35fa-450a-abd6-da266461cb78" alt="logo" tabindex="0" loading="lazy"><figcaption>logo</figcaption></figure><hr><h2 id="title-drive-wmorder-9分享人-张明珠" tabindex="-1"><a class="header-anchor" href="#title-drive-wmorder-9分享人-张明珠"><span>Title: Drive-WM Order: 9 分享人：张明珠</span></a></h2><h2 id="分享摘要" tabindex="-1"><a class="header-anchor" href="#分享摘要"><span>分享摘要</span></a></h2><p>关键词： 世界模型；端到端；多视角； 分享简要： 针对自动驾驶中如何提前预测未来事件并评估可预见风险的问题，我们受到潜在视频扩散模型的启发，提出了一种名为Drive-WM的多视点驾驶世界模型方法。该方法增强了端到端自动驾驶的通用性和安全性，提高了自动驾驶车辆在复杂场景中的规划能力。 创新： 1.引入多视图和时间建模，通过联合生成多个视图和帧，提升了视频生成的质量和一致性。 2.提出视图分解建模，通过预测以相邻视图为条件的中间视图，大幅增强了多视图一致性。 3.设计统一条件接口，支持图像、文本、3D布局和操作等异构条件输入，简化了条件生成过程。</p><h2 id="会议链接" tabindex="-1"><a class="header-anchor" href="#会议链接"><span>会议链接</span></a></h2>',6),w={href:"https://meeting.tencent.com/crm/ldW0Px1da0",target:"_blank",rel:"noopener noreferrer"},k=i('<h2 id="总结收获" tabindex="-1"><a class="header-anchor" href="#总结收获"><span>总结收获</span></a></h2><p>1.关注思想而非细节</p><p>在阅读论文时，不要过于纠结具体的训练过程，而应关注其核心思想，因为训练成本往往很高。例如，训练一个8B模型需要四张A100显卡，但全量训练仍然跑不起来。而轻量化的模型可以在一天内完成一轮训练，甚至半天即可完成，适合更小规模的数据集。</p><p>2.微调和创新的差异</p><p>当前许多研究更倾向于微调模型或进行适应性应用，而非从头训练大模型。真正进行大模型训练的通常是与企业合作的团队。大模型的研究往往因其开创性而获得认可，即使实现不够完善，也因其“第一个”提出的地位而具有价值。</p><p>3.端到端结合与成本问题</p><p>将端到端方法与世界模型结合起来的研究虽然成本极高，但思想值得借鉴。训练时间虽短（如三天），但实际资源需求巨大，例如使用八张显卡连续运行多天。研究的意义在于提出了基于想象和反思的评估方法，这是可应用于其他领域的通用思想。</p><p>4.实验设计与指标设定</p><p>论文中提出的实验设计和指标设定也是学习的重点。例如，作者通过结合生成模型和扩散模型，提出了一种联合训练的方式，并设定了新的评估指标。虽然实验可能不够完善，但通过巧妙的实验设计，突出了模型的优势。</p><p>5.场景与指标的启发</p><p>论文中的实验场景和指标设定具有启发性。例如，夜间场景的生成虽然概念较为初步，但可以通过设计量化指标（如轨迹是否合理、是否发生碰撞）来评估模型性能。这种方法可以结合强化学习进行优化，并通过轻量化模型快速实现。</p><p>6.未来方向与建议</p><p>聚焦未被深入研究的领域，如夜间场景生成及其量化评估。 借助轻量化模型，快速验证新想法，例如基于想象的场景生成。 设计简单易行的评估方式，如基于轨迹合理性或地图碰撞情况的指标。</p><h2 id="问答简记" tabindex="-1"><a class="header-anchor" href="#问答简记"><span>问答简记</span></a></h2><p>1.问：扩散模型在自动驾驶和机械臂领域应用如何？</p><p>答（讲者）：</p><p>扩散模型目前在端到端方法中非常流行，无论是机械臂还是自动驾驶，都有很多相关研究。扩散模型生成画面后，会通过奖励函数对图片进行评价，得分高的图片对应的方案会被选入规划器进行执行。</p><p>2.问：扩散模型是否有碰撞率指标？</p><p>答（讲者）：</p><p>论文中有明确提到碰撞率指标。扩散模型通过生成多种可能的图片，并基于奖励函数选择最优方案，从而降低了碰撞率。</p><p>规划。</p><p>3.关于实验设计与实现细节 问：论文中使用了什么硬件配置？训练成本如何？</p><p>答（讲者）：</p><p>论文中提到训练使用了8张A40显卡，耗时三天。但代码和预训练权重未开源。训练成本非常高，例如，训练一个8B模型需要四张A100显卡，但仍可能无法跑全量。而轻量化模型一天甚至半天就能完成一轮训练，非常适合资源有限的研究。</p><p>4.问：扩散模型的分辨率对性能有什么影响？</p><p>答（讲者）：</p><p>扩散模型的生成质量与分辨率密切相关。高分辨率（如192×384或更高）能显著提升效果，但对硬件要求较高。低分辨率不仅影响生成质量，也会导致模型难以识别场景。</p><p>5.问：扩散模型如何通过“想象”进行规划？</p><p>答（讲者）：</p><p>扩散模型通过“想象”未来的时间步（如T+K、T+2K）进行规划：</p><p>当前时刻生成多个可能的图片，并基于奖励函数选择最优方案。 执行后再次观测当前状态，并重新生成下一步的规划，形成循环优化。 这种基于想象和反思的思路在超分辨率和其他领域也很常见，具有很高的通用性。</p><p>6.问：论文的实验设计有什么值得借鉴的地方？</p><p>答（讲者）：</p><p>论文通过巧妙的实验设计和新指标（如基于GPT的评估）突出了模型的优势。实验场景的设定（如夜间场景）和指标设计（如碰撞率、轨迹合理性）值得借鉴。虽然实验可能不够完善，但通过这些设计，论文很好地展示了模型的优势。</p><p>7.问：未来的研究方向有哪些建议？</p><p>答（讲者）：</p><p>探索未被深入研究的领域，例如夜间场景的性能评估。 结合基于想象和反思的评估方法，优化模型的规划能力。 借助轻量化模型，快速验证新想法，如基于想象的场景生成。</p><h2 id="总结核心思想-世界模型通过基于想象和反馈的生成与评估方法-显著提升了端到端规划的性能。实验设计-论文中巧妙的多视角场景设定和新指标是亮点-值得借鉴。资源限制-全量训练成本高昂-建议利用预训练模型或轻量化实现快速验证新想法。未来方向-探索夜间场景的性能评估、基于想象的规划优化-以及扩散模型在其他领域的应用潜力。" tabindex="-1"><a class="header-anchor" href="#总结核心思想-世界模型通过基于想象和反馈的生成与评估方法-显著提升了端到端规划的性能。实验设计-论文中巧妙的多视角场景设定和新指标是亮点-值得借鉴。资源限制-全量训练成本高昂-建议利用预训练模型或轻量化实现快速验证新想法。未来方向-探索夜间场景的性能评估、基于想象的规划优化-以及扩散模型在其他领域的应用潜力。"><span>总结 核心思想：世界模型通过基于想象和反馈的生成与评估方法，显著提升了端到端规划的性能。 实验设计：论文中巧妙的多视角场景设定和新指标是亮点，值得借鉴。 资源限制：全量训练成本高昂，建议利用预训练模型或轻量化实现快速验证新想法。 未来方向：探索夜间场景的性能评估、基于想象的规划优化，以及扩散模型在其他领域的应用潜力。</span></a></h2><h2 id="相关论文" tabindex="-1"><a class="header-anchor" href="#相关论文"><span>相关论文</span></a></h2><p>1、Magicdrive: Street view generation with diverse 3d geometry control.<br> 2、Drivegan: Towards a controllable high-quality neural simulation<br> 3、 Bevcontrol: Accurately controlling streetview elements with multi-perspective consistency via bevsketch layout</p>',40);function x(z,D){const n=o("ExternalLinkIcon");return l(),s("div",null,[h,r("p",null,[r("a",d,[e("Yuqi Wang*"),t(n)]),e(", "),r("a",c,[e("Jiawei He*"),t(n)]),e(", "),r("a",u,[e("Lue Fan*"),t(n)]),e(", "),r("a",g,[e("Hongxin Li*"),t(n)]),e(", "),r("a",_,[e("Yuntao Chen†"),t(n)]),e(", "),r("a",m,[e("Zhaoxiang Zhang†"),t(n)]),e(" (*: Equal Contribution; †: Corresponding Author)")]),r("p",null,[e("["),r("a",v,[e("arXiv"),t(n)]),e("] ["),r("a",f,[e("Project page"),t(n)]),e("]")]),b,r("p",null,[r("a",w,[e("腾讯会议链接"),t(n)])]),k])}const A=a(p,[["render",x],["__file","241230_Drive_WM_CVPR24_zmz.html.vue"]]),P=JSON.parse('{"path":"/browser/epoch_two_24_1209_25_0120/241230_Drive_WM_CVPR24_zmz.html","title":"","lang":"en-US","frontmatter":{"feed":false,"seo":false,"head":[]},"headers":[{"level":2,"title":"Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving（驶向未来：利用自动驾驶世界模型进行多视图视觉预测和规划）","slug":"driving-into-the-future-multiview-visual-forecasting-and-planning-with-world-model-for-autonomous-driving-驶向未来-利用自动驾驶世界模型进行多视图视觉预测和规划","link":"#driving-into-the-future-multiview-visual-forecasting-and-planning-with-world-model-for-autonomous-driving-驶向未来-利用自动驾驶世界模型进行多视图视觉预测和规划","children":[]},{"level":2,"title":"Title: Drive-WMOrder: 9分享人：张明珠","slug":"title-drive-wmorder-9分享人-张明珠","link":"#title-drive-wmorder-9分享人-张明珠","children":[]},{"level":2,"title":"分享摘要","slug":"分享摘要","link":"#分享摘要","children":[]},{"level":2,"title":"会议链接","slug":"会议链接","link":"#会议链接","children":[]},{"level":2,"title":"总结收获","slug":"总结收获","link":"#总结收获","children":[]},{"level":2,"title":"问答简记","slug":"问答简记","link":"#问答简记","children":[]},{"level":2,"title":"总结核心思想：世界模型通过基于想象和反馈的生成与评估方法，显著提升了端到端规划的性能。实验设计：论文中巧妙的多视角场景设定和新指标是亮点，值得借鉴。资源限制：全量训练成本高昂，建议利用预训练模型或轻量化实现快速验证新想法。未来方向：探索夜间场景的性能评估、基于想象的规划优化，以及扩散模型在其他领域的应用潜力。","slug":"总结核心思想-世界模型通过基于想象和反馈的生成与评估方法-显著提升了端到端规划的性能。实验设计-论文中巧妙的多视角场景设定和新指标是亮点-值得借鉴。资源限制-全量训练成本高昂-建议利用预训练模型或轻量化实现快速验证新想法。未来方向-探索夜间场景的性能评估、基于想象的规划优化-以及扩散模型在其他领域的应用潜力。","link":"#总结核心思想-世界模型通过基于想象和反馈的生成与评估方法-显著提升了端到端规划的性能。实验设计-论文中巧妙的多视角场景设定和新指标是亮点-值得借鉴。资源限制-全量训练成本高昂-建议利用预训练模型或轻量化实现快速验证新想法。未来方向-探索夜间场景的性能评估、基于想象的规划优化-以及扩散模型在其他领域的应用潜力。","children":[]},{"level":2,"title":"相关论文","slug":"相关论文","link":"#相关论文","children":[]}],"git":{"createdTime":1732274117000,"updatedTime":1736253512000,"contributors":[{"name":"mingzhuzhang1","email":"145547769+mingzhuzhang1@users.noreply.github.com","commits":2}]},"readingTime":{"minutes":6.22,"words":1865},"filePathRelative":"browser/epoch_two_24_1209_25_0120/241230_Drive_WM_CVPR24_zmz.md","localizedDate":"November 22, 2024"}');export{A as comp,P as data};
