import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as i,o as l,c as s,a as e,b as r,d as n,f as t}from"./app-Bar_WE1N.js";const d={},h=t('<h1 id="world-models-autonomous-driving-latest-survey" tabindex="-1"><a class="header-anchor" href="#world-models-autonomous-driving-latest-survey"><span>World-Models-Autonomous-Driving-Latest-Survey</span></a></h1><p>A curated list of world model for autonmous driving. Keep updated.</p><h2 id="📌-introduction" tabindex="-1"><a class="header-anchor" href="#📌-introduction"><span>📌 Introduction</span></a></h2><h2 id="✧-世界模型用于自动驾驶场景生成相关文献整理" tabindex="-1"><a class="header-anchor" href="#✧-世界模型用于自动驾驶场景生成相关文献整理"><span>✧ 世界模型用于自动驾驶场景生成相关文献整理</span></a></h2><h2 id="➢-论文汇总" tabindex="-1"><a class="header-anchor" href="#➢-论文汇总"><span>➢ 论文汇总</span></a></h2>',5),c={href:"https://github.com/GigaAI-research/General-World-Models-Survey",target:"_blank",rel:"noopener noreferrer"},u={href:"https://github.com/HaoranZhuExplorer/World-Models-Autonomous-Driving-Latest-Survey",target:"_blank",rel:"noopener noreferrer"},p={href:"https://github.com/zhanghm1995/awesome-world-models-for-AD?tab=readme-ov-file#Table-of-Content",target:"_blank",rel:"noopener noreferrer"},g={href:"https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving/blob/main/papers.md#world-model--model-based-rl",target:"_blank",rel:"noopener noreferrer"},m={href:"https://github.com/chaytonmin/Awesome-Papers-World-Models-Autonomous-Driving",target:"_blank",rel:"noopener noreferrer"},_=e("h2",{id:"➢-认识世界模型",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-认识世界模型"},[e("span",null,"➢ 认识世界模型")])],-1),f=e("h3",{id:"_1-简单介绍-从世界模型-自动驾驶世界模型用于场景生成",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_1-简单介绍-从世界模型-自动驾驶世界模型用于场景生成"},[e("span",null,"1. 简单介绍（从世界模型--> 自动驾驶世界模型用于场景生成）")])],-1),v={href:"https://mp.weixin.qq.com/s/UmT0DjFqRPsjv2m28ySvdw",target:"_blank",rel:"noopener noreferrer"},b={href:"https://arxiv.org/abs/1803.10122",target:"_blank",rel:"noopener noreferrer"},w={href:"https://worldmodels.github.io/",target:"_blank",rel:"noopener noreferrer"},k={href:"https://www.bilibili.com/read/cv34465959/",target:"_blank",rel:"noopener noreferrer"},D={href:"https://blog.csdn.net/CV_Autobot/article/details/134002647",target:"_blank",rel:"noopener noreferrer"},A=e("h3",{id:"_2-论文综述",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-论文综述"},[e("span",null,"2.论文综述")])],-1),y=e("strong",null,[e("code",null,"arxiv")],-1),x={href:"https://arxiv.org/abs/2403.02622",target:"_blank",rel:"noopener noreferrer"},M={href:"https://arxiv.org/abs/2403.02622",target:"_blank",rel:"noopener noreferrer"},W=e("strong",null,[e("code",null,"arxiv")],-1),P={href:"https://arxiv.org/pdf/2401.12888.pdf",target:"_blank",rel:"noopener noreferrer"},I=e("strong",null,[e("code",null,"arxiv")],-1),S={href:"https://arxiv.org/pdf/2401.08045.pdf",target:"_blank",rel:"noopener noreferrer"},C=e("h2",{id:"_3-挑战赛-workshops-challenges",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_3-挑战赛-workshops-challenges"},[e("span",null,"3.挑战赛 Workshops/Challenges")])],-1),T=e("strong",null,[e("code",null,"Challenges")],-1),L={href:"https://github.com/1x-technologies/1xgpt",target:"_blank",rel:"noopener noreferrer"},V=e("strong",null,[e("code",null,"Challenges")],-1),G={href:"https://opendrivelab.com/challenge2024/",target:"_blank",rel:"noopener noreferrer"},E=e("h2",{id:"tutorials-talks",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#tutorials-talks"},[e("span",null,"Tutorials/Talks/")])],-1),R=e("strong",null,[e("code",null,"from Wayve")],-1),N={href:"https://www.youtube.com/watch?v=lNOs08byOhw",target:"_blank",rel:"noopener noreferrer"},O={href:"https://www.youtube.com/watch?v=wMvYjiv6EpY",target:"_blank",rel:"noopener noreferrer"},U=e("h2",{id:"➢-优秀团队-学术大佬-公司",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-优秀团队-学术大佬-公司"},[e("span",null,"➢ 优秀团队 / 学术大佬/ 公司")])],-1),z={id:"■-上海ailab-上海人工智能实验室-https-opendrivelab-com-publications",tabindex:"-1"},q={class:"header-anchor",href:"#■-上海ailab-上海人工智能实验室-https-opendrivelab-com-publications"},B={href:"https://opendrivelab.com/publications/",target:"_blank",rel:"noopener noreferrer"},F={id:"■-香港中文大学-陈铠老师团队-geometric-controllable-visual-generation-a-systematic-solution-video",tabindex:"-1"},K={class:"header-anchor",href:"#■-香港中文大学-陈铠老师团队-geometric-controllable-visual-generation-a-systematic-solution-video"},j={href:"https://www.bilibili.com/video/BV18T421v7Nf/?spm_id_from=333.337.search-card.all.click",target:"_blank",rel:"noopener noreferrer"},J={id:"■-极佳科技-极佳科技drivedreamer自动驾驶世界模型、worlddreamer通用世界模型目前已成功商业化落地。-推文",tabindex:"-1"},H={class:"header-anchor",href:"#■-极佳科技-极佳科技drivedreamer自动驾驶世界模型、worlddreamer通用世界模型目前已成功商业化落地。-推文"},X={href:"https://baijiahao.baidu.com/s?id=1799624134723943641",target:"_blank",rel:"noopener noreferrer"},Z=e("h4",{id:"■-wayve、tesla、旷视、中科院自动化所",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#■-wayve、tesla、旷视、中科院自动化所"},[e("span",null,"■ Wayve、Tesla、旷视、中科院自动化所")])],-1),Y={id:"■-蔚来车企-https-www-qbitai-com-2024-07-172025-html",tabindex:"-1"},Q={class:"header-anchor",href:"#■-蔚来车企-https-www-qbitai-com-2024-07-172025-html"},$={href:"https://www.qbitai.com/2024/07/172025.html",target:"_blank",rel:"noopener noreferrer"},ee=t('<h2 id="➢-经典论文-推荐加-👍" tabindex="-1"><a class="header-anchor" href="#➢-经典论文-推荐加-👍"><span>➢ 经典论文：（推荐加“👍”）</span></a></h2><h4 id="world-models-are-adept-at-representing-an-agent-s-spatio-temporal-knowledge-about-its-environment-through-the-prediction-of-future-changes" tabindex="-1"><a class="header-anchor" href="#world-models-are-adept-at-representing-an-agent-s-spatio-temporal-knowledge-about-its-environment-through-the-prediction-of-future-changes"><span>World Models are adept at representing an agent&#39;s spatio-temporal knowledge about its environment through the prediction of future changes.</span></a></h4><h4 id="there-are-two-main-types-of-world-models-in-autonomous-driving-aimed-at-reducing-driving-uncertainty-i-e-world-model-as-neural-driving-simulator-and-world-model-for-end-to-end-driving" tabindex="-1"><a class="header-anchor" href="#there-are-two-main-types-of-world-models-in-autonomous-driving-aimed-at-reducing-driving-uncertainty-i-e-world-model-as-neural-driving-simulator-and-world-model-for-end-to-end-driving"><span>There are two main types of world models in Autonomous Driving aimed at reducing driving uncertainty, i.e., World Model as Neural Driving Simulator and World Model for End-to-end Driving.</span></a></h4><h4 id="in-the-real-environment-methods-like-gaia-1-and-copilot4d-involve-utilizing-generative-models-to-construct-neural-simulators-that-produce-2d-or-3d-future-scenes-to-enhance-predictive-capabilities" tabindex="-1"><a class="header-anchor" href="#in-the-real-environment-methods-like-gaia-1-and-copilot4d-involve-utilizing-generative-models-to-construct-neural-simulators-that-produce-2d-or-3d-future-scenes-to-enhance-predictive-capabilities"><span>In the real environment, methods like GAIA-1 and Copilot4D involve utilizing generative models to construct neural simulators that produce 2D or 3D future scenes to enhance predictive capabilities.</span></a></h4><h4 id="in-the-simulation-environment-methods-such-as-mile-and-trafficbots-are-based-on-reinforcement-learning-enhancing-their-capacity-for-decision-making-and-future-prediction-thereby-paving-the-way-to-end-to-end-autonomous-driving" tabindex="-1"><a class="header-anchor" href="#in-the-simulation-environment-methods-such-as-mile-and-trafficbots-are-based-on-reinforcement-learning-enhancing-their-capacity-for-decision-making-and-future-prediction-thereby-paving-the-way-to-end-to-end-autonomous-driving"><span>In the simulation environment, methods such as MILE and TrafficBots are based on reinforcement learning, enhancing their capacity for decision-making and future prediction, thereby paving the way to end-to-end autonomous driving.</span></a></h4><h3 id="neural-driving-simulator-based-on-world-models" tabindex="-1"><a class="header-anchor" href="#neural-driving-simulator-based-on-world-models"><span>Neural Driving Simulator based on World Models</span></a></h3><h4 id="_2d-scene-generation" tabindex="-1"><a class="header-anchor" href="#_2d-scene-generation"><span>2D Scene Generation</span></a></h4>',7),re={href:"https://arxiv.org/abs/2309.17080",target:"_blank",rel:"noopener noreferrer"},oe={href:"https://wayve.ai/thinking/scaling-gaia-1/",target:"_blank",rel:"noopener noreferrer"},ne={href:"https://www.youtube.com/watch?v=6x-Xb_uT7ts",target:"_blank",rel:"noopener noreferrer"},te={href:"https://drivedreamer.github.io/",target:"_blank",rel:"noopener noreferrer"},ae={href:"https://github.com/JeffWang987/DriveDreamer",target:"_blank",rel:"noopener noreferrer"},ie={href:"https://arxiv.org/abs/2311.13549",target:"_blank",rel:"noopener noreferrer"},le={href:"https://arxiv.org/abs/2310.07771",target:"_blank",rel:"noopener noreferrer"},se={href:"https://panacea-ad.github.io/",target:"_blank",rel:"noopener noreferrer"},de={href:"https://github.com/wenyuqing/panacea",target:"_blank",rel:"noopener noreferrer"},he={href:"https://drive-wm.github.io/",target:"_blank",rel:"noopener noreferrer"},ce={href:"https://github.com/BraveGroup/Drive-WM",target:"_blank",rel:"noopener noreferrer"},ue={href:"https://arxiv.org/abs/2312.02934",target:"_blank",rel:"noopener noreferrer"},pe={href:"https://drivedreamer2.github.io/",target:"_blank",rel:"noopener noreferrer"},ge={href:"https://github.com/f1yfisher/DriveDreamer2",target:"_blank",rel:"noopener noreferrer"},me={href:"https://arxiv.org/abs/2403.09630",target:"_blank",rel:"noopener noreferrer"},_e={href:"https://github.com/OpenDriveLab/DriveAGI?tab=readme-ov-file",target:"_blank",rel:"noopener noreferrer"},fe={href:"https://subjectdrive.github.io/",target:"_blank",rel:"noopener noreferrer"},ve=e("h4",{id:"_3d-scene-generation",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_3d-scene-generation"},[e("span",null,"3D Scene Generation")])],-1),be={href:"https://arxiv.org/abs/2311.01017",target:"_blank",rel:"noopener noreferrer"},we={href:"https://arxiv.org/abs/2311.16038",target:"_blank",rel:"noopener noreferrer"},ke={href:"https://github.com/wzzheng/OccWorld",target:"_blank",rel:"noopener noreferrer"},De={href:"https://arxiv.org/abs/2311.11762",target:"_blank",rel:"noopener noreferrer"},Ae={href:"https://www.zyrianov.org/lidardm/",target:"_blank",rel:"noopener noreferrer"},ye={href:"https://github.com/vzyrianov/lidardm",target:"_blank",rel:"noopener noreferrer"},xe=e("h4",{id:"_4d-pre-training-for-autonomous-driving",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_4d-pre-training-for-autonomous-driving"},[e("span",null,"4D Pre-training for Autonomous Driving")])],-1),Me={href:"https://arxiv.org/abs/2308.07234",target:"_blank",rel:"noopener noreferrer"},We={href:"https://arxiv.org/abs/2312.17655",target:"_blank",rel:"noopener noreferrer"},Pe={href:"https://github.com/OpenDriveLab/ViDAR",target:"_blank",rel:"noopener noreferrer"},Ie=e("li",null,[r("👍(2024 CVPR) DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving ["),e("a",{href:"XXX"},"Paper"),r("] (PKU)")],-1),Se=e("h3",{id:"end-to-end-driving-based-on-world-models",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#end-to-end-driving-based-on-world-models"},[e("span",null,"End-to-end Driving based on World Models")])],-1),Ce={href:"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9316769afaaeeaad42a9e3633b14e801-Abstract-Conference.html",target:"_blank",rel:"noopener noreferrer"},Te={href:"https://proceedings.neurips.cc/paper_files/paper/2022/hash/827cb489449ea216e4a257c47e407d18-Abstract-Conference.html",target:"_blank",rel:"noopener noreferrer"},Le={href:"https://github.com/wayveai/mile",target:"_blank",rel:"noopener noreferrer"},Ve={href:"https://arxiv.org/abs/2210.04017",target:"_blank",rel:"noopener noreferrer"},Ge={href:"https://ieeexplore.ieee.org/abstract/document/10161243",target:"_blank",rel:"noopener noreferrer"},Ee={href:"https://arxiv.org/abs/2402.16720",target:"_blank",rel:"noopener noreferrer"},Re=e("h3",{id:"others",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#others"},[e("span",null,"Others")])],-1),Ne={href:"http://www.sci.brooklyn.cuny.edu/~parsons/courses/3415-fall-2011/papers/elfes.pdf",target:"_blank",rel:"noopener noreferrer"},Oe=e("h2",{id:"➢-经典项目",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-经典项目"},[e("span",null,"➢ 经典项目")])],-1),Ue={href:"https://github.com/cvlab-yonsei/MNAD",target:"_blank",rel:"noopener noreferrer"},ze=t('<h2 id="➢-发现的新的有意思的研究方向" tabindex="-1"><a class="header-anchor" href="#➢-发现的新的有意思的研究方向"><span>➢ 发现的新的有意思的研究方向--&gt;</span></a></h2><p>生成式的World Model可以被用来当作一种仿真工具来生成仿真数据，特别是极为少见的Corner Case的数据。 然而World Model更有潜力的应用方向是World Model可能会成为像GPT一样的自动驾驶领域的基础模型，而其他自动驾驶具体任务都会围绕这个基础模型进行研发构建。</p><h3 id="_1-definition" tabindex="-1"><a class="header-anchor" href="#_1-definition"><span>1. DEFINITION</span></a></h3><p>The aim of this TASK is to detect and automatically generate high-level explanations of anomalous events in video. Understanding the cause of an anomalous event is crucialas the required response is dependant on its nature andseverity. --&gt; Anomaly Detection &amp; Anoamly Explanation</p><h3 id="_2-related-work" tabindex="-1"><a class="header-anchor" href="#_2-related-work"><span>2. RELATED WORK</span></a></h3><p>[1] Joint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge (ICCV 2017)<br> [2] X-MAN: Explaining multiple sources of anomalies in video (CVPR workshop 2021)<br> [3] Discrete neural representations for explainable anomaly detection (WACV 2022)</p>',6);function qe(Be,Fe){const o=i("ExternalLinkIcon");return l(),s("div",null,[h,e("p",null,[r("[1] "),e("a",c,[r("https://github.com/GigaAI-research/General-World-Models-Survey"),n(o)]),r(" 该 repo 内有目前世界模型方向的优秀论文汇总，包括基本分类：视频生成、自动驾驶和自主代理。其中自动驾驶分成端到端、以及2D、3D神经模拟器方法。世界模型的文献、 开源code、 综述。")]),e("p",null,[r("[2] "),e("a",u,[r("https://github.com/HaoranZhuExplorer/World-Models-Autonomous-Driving-Latest-Survey"),n(o)]),r(" 该repo 内以‘时间’为顺序精选相关世界自动驾驶模型。且并持续更新，包括一些挑战、相关视频，包括机器人领域的世界模型使用（大多数为模仿学习强化学习方向）可参考借鉴。")]),e("p",null,[r("[3] "),e("a",p,[r("Awesome-World-Models-for-AD "),n(o)])]),e("p",null,[r("[4] "),e("a",g,[r("World models paper list from Shanghai AI lab"),n(o)])]),e("p",null,[r("[5] "),e("a",m,[r("Awesome-Papers-World-Models-Autonomous-Driving"),n(o)]),r(".")]),_,f,e("p",null,[r("[1] 世界模型简介："),e("a",v,[r("https://mp.weixin.qq.com/s/UmT0DjFqRPsjv2m28ySvdw"),n(o)]),r("世界模型是一种人工智能技术，旨在通过整合多种感知信息，如视觉、听觉和语言，利用机器学习和深度学习等方法来理解和预测现实世界。它包括感知模块、表征学习、动力学模型和生成模型，用于构建环境的内部表示，不仅能反映当前状态，还能预测未来变化。这种模型在强化学习、自动驾驶、游戏开发和机器人学等领域有广泛应用。Yann LeCun提出的这一概念，强调通过自监督学习让AI像人一样理解世界，形成内部的心理表征，以期实现通用人工智能。Meta的I-JEPA模型是基于这一愿景的实现，它通过分析和补全图像展示了对世界背景知识的应用。")]),e("p",null,[r("[2] 影响较大的早期世界模型文章：2018年Jurgen在NeurIPS 以循环世界模型促进策略演变“Recurrent World Models Facilitate Policy Evolution”的title发表：链接: "),e("a",b,[r("https://arxiv.org/abs/1803.10122"),n(o)]),r(" 示例: "),e("a",w,[r("https://worldmodels.github.io/"),n(o)])]),e("p",null,[r("[3] 世界模型在自动驾驶领域的应用： "),e("a",k,[r("https://www.bilibili.com/read/cv34465959/"),n(o)])]),e("p",null,[r("[4] 世界模型用于自动驾驶场景生成以及仿真平台: "),e("a",D,[r("https://blog.csdn.net/CV_Autobot/article/details/134002647"),n(o)])]),A,e("p",null,[r("[1] 2024-Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond， "),y,r(),e("a",x,[r("Paper"),n(o)]),r(" 极佳科技 （比较全面，该综述通过 260 余篇文献，对世界模型在视频生成、自动驾驶、智能体、通用机器人等领域的研究和应用进行了详尽的分析和讨论。另外，该综述还审视了当前世界模型的挑战和局限性，并展望了它们未来的发展方向。）")]),e("p",null,[r("[2] 2024-World Models for Autonomous Driving: An Initial Survey，IEEE TIV,澳门大学，夏威夷大学。"),e("a",M,[r("Paper"),n(o)]),r("（画风有趣，对自动驾驶世界模型的现状和未来进展进行了初步回顾，涵盖了它们的理论基础、实际应用以及旨在克服现有局限性的正在进行的研究工作。）")]),e("p",null,[r("[3]2024-Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies "),W,r(),e("a",P,[r("Paper"),n(o)])]),e("p",null,[r("[4]2024-Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities "),I,r(),e("a",S,[r("Paper"),n(o)])]),C,e("ul",null,[e("li",null,[e("p",null,[r("2024-1X World Model Challenge "),T,r(),e("a",L,[r("Link"),n(o)])])]),e("li",null,[e("p",null,[r("2024-CVPR Workshop, Foundation Models for Autonomous Systems, Challenges, Track 4: Predictive World Model "),V,r(),e("a",G,[r("Link"),n(o)])])])]),E,e("ul",null,[e("li",null,[e("p",null,[r("2023 "),R,r("; "),e("a",N,[r("Video"),n(o)])])]),e("li",null,[e("p",null,[r("2022-Neural World Models for Autonomous Driving "),e("a",O,[r("Video"),n(o)])])])]),U,e("h4",z,[e("a",q,[e("span",null,[r("■ 上海AILab（上海人工智能实验室） "),e("a",B,[r("https://opendrivelab.com/publications/"),n(o)])])])]),e("h4",F,[e("a",K,[e("span",null,[r("■ 香港中文大学（陈铠老师团队）Geometric-Controllable Visual Generation: A Systematic Solution "),e("a",j,[r("Video"),n(o)])])])]),e("h4",J,[e("a",H,[e("span",null,[r("■ 极佳科技（极佳科技DriveDreamer自动驾驶世界模型、WorldDreamer通用世界模型目前已成功商业化落地。）"),e("a",X,[r("推文"),n(o)])])])]),Z,e("h4",Y,[e("a",Q,[e("span",null,[r("■ 蔚来车企："),e("a",$,[r("https://www.qbitai.com/2024/07/172025.html"),n(o)])])])]),ee,e("ul",null,[e("li",null,[r("👍(2023 Arxiv) GAIA-1: A generative world model for autonomous driving ["),e("a",re,[r("Paper"),n(o)]),r("]["),e("a",oe,[r("Blog"),n(o)]),r("] (Wayve)")]),e("li",null,[r("(2023 CVPR 2023 workshop) ["),e("a",ne,[r("Video"),n(o)]),r("] (Tesla)")]),e("li",null,[r("👍(2023 Arxiv) DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving ["),e("a",te,[r("Paper"),n(o)]),r("]["),e("a",ae,[r("Code"),n(o)]),r("] (GigaAI)")]),e("li",null,[r("(2023 Arxiv) ADriver-I: A General World Model for Autonomous Driving ["),e("a",ie,[r("Paper"),n(o)]),r("] (MEGVII)")]),e("li",null,[r("👍(2023 Arxiv) DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model ["),e("a",le,[r("Paper"),n(o)]),r("] (Baidu)")]),e("li",null,[r("(2023 Arxiv) Panacea: Panoramic and Controllable Video Generation for Autonomous Driving ["),e("a",se,[r("Paper"),n(o)]),r("]["),e("a",de,[r("Code"),n(o)]),r("] (MEGVII)")]),e("li",null,[r("👍(2024 CVPR) Drive-WM: Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving ["),e("a",he,[r("Paper"),n(o)]),r("]["),e("a",ce,[r("Code"),n(o)]),r("] (CASIA)")]),e("li",null,[r("(2023 Arxiv) WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera Driving Scene Generation ["),e("a",ue,[r("Paper"),n(o)]),r("] (Fudan)")]),e("li",null,[r("(2024 Arxiv) DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation ["),e("a",pe,[r("Paper"),n(o)]),r("]["),e("a",ge,[r("Code"),n(o)]),r("] (GigaAI)")]),e("li",null,[r("(2024 CVPR) GenAD: Generalized Predictive Model for Autonomous Driving ["),e("a",me,[r("Paper"),n(o)]),r("]["),e("a",_e,[r("Code"),n(o)]),r("] (Shanghai AI Lab)")]),e("li",null,[r("(2024 Arxiv) SubjectDrive: Scaling Generative Data in Autonomous Driving via Subject Control ["),e("a",fe,[r("Paper"),n(o)]),r("] (MEGVII)")])]),ve,e("ul",null,[e("li",null,[r("👍(2024 ICLR) Copilot4D:Learning unsupervised world models for autonomous driving via discrete diffusion ["),e("a",be,[r("Paper"),n(o)]),r("] (Waabi)")]),e("li",null,[r("(2023 Arxiv) OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving ["),e("a",we,[r("Paper"),n(o)]),r("]["),e("a",ke,[r("Code"),n(o)]),r("] (THU)")]),e("li",null,[r("(2023 Arxiv) MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations ["),e("a",De,[r("Paper"),n(o)]),r("] (KIT)")]),e("li",null,[r("(2024 Arxiv) LidarDM: Generative LiDAR Simulation in a Generated World ["),e("a",Ae,[r("Paper"),n(o)]),r("]["),e("a",ye,[r("Code"),n(o)]),r("] (MIT)")])]),xe,e("ul",null,[e("li",null,[r("(2023 Arxiv) UniWorld: Autonomous Driving Pre-training via World Models ["),e("a",Me,[r("Paper"),n(o)]),r("] (PKU)")]),e("li",null,[r("(2024 CVPR) ViDAR: Visual Point Cloud Forecasting enables Scalable Autonomous Driving ["),e("a",We,[r("Paper"),n(o)]),r("]["),e("a",Pe,[r("Code"),n(o)]),r("] (Shanghai AI Lab)")]),Ie]),Se,e("ul",null,[e("li",null,[r("👍(2022 NeurIPS) Iso-Dream: Isolating and Leveraging Noncontrollable Visual Dynamics in World Models ["),e("a",Ce,[r("Paper"),n(o)]),r("] (SJTU)")]),e("li",null,[r("👍(2022 NeurIPS) MILE: Model-Based Imitation Learning for Urban Driving ["),e("a",Te,[r("Paper"),n(o)]),r("]["),e("a",Le,[r("Code"),n(o)]),r("] (Wayve)")]),e("li",null,[r("(2022 NeurIPS Deep RL Workshop) SEM2: Enhance Sample Efficiency and Robustness of End-to-end Urban Autonomous Driving via Semantic Masked World Model ["),e("a",Ve,[r("Paper"),n(o)]),r("] (HIT & THU)")]),e("li",null,[r("(2023 ICRA) TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction ["),e("a",Ge,[r("Paper"),n(o)]),r("] (ETH Zurich)")]),e("li",null,[r("(2024 Arxiv) Think2Drive: Efficient Reinforcement Learning by Thinking in Latent World Model for Quasi-Realistic Autonomous Driving (in CARLA-v2) ["),e("a",Ee,[r("Paper"),n(o)]),r("] (SJTU)")])]),Re,e("ul",null,[e("li",null,[r("(1989) Using Occupancy Grids for Mobile Robot Perception and Navigation ["),e("a",Ne,[r("paper"),n(o)]),r("]")])]),Oe,e("p",null,[r("○ MNAD --> "),e("a",Ue,[r("https://github.com/cvlab-yonsei/MNAD"),n(o)]),r(" 可作为baseline.")]),ze])}const Je=a(d,[["render",qe],["__file","generation.html.vue"]]),He=JSON.parse('{"path":"/worldmodel/generation.html","title":"World-Models-Autonomous-Driving-Latest-Survey","lang":"en-US","frontmatter":{"description":"World-Models-Autonomous-Driving-Latest-Survey A curated list of world model for autonmous driving. Keep updated. 📌 Introduction ✧ 世界模型用于自动驾驶场景生成相关文献整理 ➢ 论文汇总 [1] https://github...","head":[["meta",{"property":"og:url","content":"https://openvisuallab.github.io/worldmodel/generation.html"}],["meta",{"property":"og:site_name","content":"OpenVisualLab"}],["meta",{"property":"og:title","content":"World-Models-Autonomous-Driving-Latest-Survey"}],["meta",{"property":"og:description","content":"World-Models-Autonomous-Driving-Latest-Survey A curated list of world model for autonmous driving. Keep updated. 📌 Introduction ✧ 世界模型用于自动驾驶场景生成相关文献整理 ➢ 论文汇总 [1] https://github..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-09-13T02:40:58.000Z"}],["meta",{"property":"article:author","content":"OpenVisualLab"}],["meta",{"property":"article:modified_time","content":"2024-09-13T02:40:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"World-Models-Autonomous-Driving-Latest-Survey\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-09-13T02:40:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OpenVisualLab\\",\\"url\\":\\"https://openvisuallab.github.io\\"}]}"]]},"headers":[{"level":2,"title":"📌 Introduction","slug":"📌-introduction","link":"#📌-introduction","children":[]},{"level":2,"title":"✧ 世界模型用于自动驾驶场景生成相关文献整理","slug":"✧-世界模型用于自动驾驶场景生成相关文献整理","link":"#✧-世界模型用于自动驾驶场景生成相关文献整理","children":[]},{"level":2,"title":"➢ 论文汇总","slug":"➢-论文汇总","link":"#➢-论文汇总","children":[]},{"level":2,"title":"➢ 认识世界模型","slug":"➢-认识世界模型","link":"#➢-认识世界模型","children":[{"level":3,"title":"1. 简单介绍（从世界模型--> 自动驾驶世界模型用于场景生成）","slug":"_1-简单介绍-从世界模型-自动驾驶世界模型用于场景生成","link":"#_1-简单介绍-从世界模型-自动驾驶世界模型用于场景生成","children":[]},{"level":3,"title":"2.论文综述","slug":"_2-论文综述","link":"#_2-论文综述","children":[]}]},{"level":2,"title":"3.挑战赛 Workshops/Challenges","slug":"_3-挑战赛-workshops-challenges","link":"#_3-挑战赛-workshops-challenges","children":[]},{"level":2,"title":"Tutorials/Talks/","slug":"tutorials-talks","link":"#tutorials-talks","children":[]},{"level":2,"title":"➢ 优秀团队 / 学术大佬/ 公司","slug":"➢-优秀团队-学术大佬-公司","link":"#➢-优秀团队-学术大佬-公司","children":[]},{"level":2,"title":"➢ 经典论文：（推荐加“👍”）","slug":"➢-经典论文-推荐加-👍","link":"#➢-经典论文-推荐加-👍","children":[{"level":3,"title":"Neural Driving Simulator based on World Models","slug":"neural-driving-simulator-based-on-world-models","link":"#neural-driving-simulator-based-on-world-models","children":[]},{"level":3,"title":"End-to-end Driving based on World Models","slug":"end-to-end-driving-based-on-world-models","link":"#end-to-end-driving-based-on-world-models","children":[]},{"level":3,"title":"Others","slug":"others","link":"#others","children":[]}]},{"level":2,"title":"➢ 经典项目","slug":"➢-经典项目","link":"#➢-经典项目","children":[]},{"level":2,"title":"➢ 发现的新的有意思的研究方向-->","slug":"➢-发现的新的有意思的研究方向","link":"#➢-发现的新的有意思的研究方向","children":[{"level":3,"title":"1. DEFINITION","slug":"_1-definition","link":"#_1-definition","children":[]},{"level":3,"title":"2. RELATED WORK","slug":"_2-related-work","link":"#_2-related-work","children":[]}]}],"git":{"createdTime":1726102486000,"updatedTime":1726195258000,"contributors":[{"name":"mingzhuzhang1","email":"145547769+mingzhuzhang1@users.noreply.github.com","commits":2}]},"readingTime":{"minutes":6.18,"words":1853},"filePathRelative":"worldmodel/generation.md","localizedDate":"September 12, 2024","excerpt":"\\n<p>A curated list of world model for autonmous driving. Keep updated.</p>\\n<h2>📌 Introduction</h2>\\n<h2>✧ 世界模型用于自动驾驶场景生成相关文献整理</h2>\\n<h2>➢ 论文汇总</h2>\\n<p>[1] <a href=\\"https://github.com/GigaAI-research/General-World-Models-Survey\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://github.com/GigaAI-research/General-World-Models-Survey</a> 该 repo 内有目前世界模型方向的优秀论文汇总，包括基本分类：视频生成、自动驾驶和自主代理。其中自动驾驶分成端到端、以及2D、3D神经模拟器方法。世界模型的文献、 开源code、 综述。</p>","autoDesc":true}');export{Je as comp,He as data};
