import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as i,o as l,c as s,a as e,b as r,d as n,f as t}from"./app-Bar_WE1N.js";const d={},h=t('<h1 id="world-models-autonomous-driving-latest-survey" tabindex="-1"><a class="header-anchor" href="#world-models-autonomous-driving-latest-survey"><span>World-Models-Autonomous-Driving-Latest-Survey</span></a></h1><p>A curated list of world model for autonmous driving. Keep updated.</p><h2 id="ğŸ“Œ-introduction" tabindex="-1"><a class="header-anchor" href="#ğŸ“Œ-introduction"><span>ğŸ“Œ Introduction</span></a></h2><h2 id="âœ§-ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†" tabindex="-1"><a class="header-anchor" href="#âœ§-ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†"><span>âœ§ ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†</span></a></h2><h2 id="â¢-è®ºæ–‡æ±‡æ€»" tabindex="-1"><a class="header-anchor" href="#â¢-è®ºæ–‡æ±‡æ€»"><span>â¢ è®ºæ–‡æ±‡æ€»</span></a></h2>',5),c={href:"https://github.com/GigaAI-research/General-World-Models-Survey",target:"_blank",rel:"noopener noreferrer"},u={href:"https://github.com/HaoranZhuExplorer/World-Models-Autonomous-Driving-Latest-Survey",target:"_blank",rel:"noopener noreferrer"},p={href:"https://github.com/zhanghm1995/awesome-world-models-for-AD?tab=readme-ov-file#Table-of-Content",target:"_blank",rel:"noopener noreferrer"},g={href:"https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving/blob/main/papers.md#world-model--model-based-rl",target:"_blank",rel:"noopener noreferrer"},m={href:"https://github.com/chaytonmin/Awesome-Papers-World-Models-Autonomous-Driving",target:"_blank",rel:"noopener noreferrer"},_=e("h2",{id:"â¢-è®¤è¯†ä¸–ç•Œæ¨¡å‹",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#â¢-è®¤è¯†ä¸–ç•Œæ¨¡å‹"},[e("span",null,"â¢ è®¤è¯†ä¸–ç•Œæ¨¡å‹")])],-1),f=e("h3",{id:"_1-ç®€å•ä»‹ç»-ä»ä¸–ç•Œæ¨¡å‹-è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ç”¨äºåœºæ™¯ç”Ÿæˆ",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_1-ç®€å•ä»‹ç»-ä»ä¸–ç•Œæ¨¡å‹-è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ç”¨äºåœºæ™¯ç”Ÿæˆ"},[e("span",null,"1. ç®€å•ä»‹ç»ï¼ˆä»ä¸–ç•Œæ¨¡å‹--> è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ç”¨äºåœºæ™¯ç”Ÿæˆï¼‰")])],-1),v={href:"https://mp.weixin.qq.com/s/UmT0DjFqRPsjv2m28ySvdw",target:"_blank",rel:"noopener noreferrer"},b={href:"https://arxiv.org/abs/1803.10122",target:"_blank",rel:"noopener noreferrer"},w={href:"https://worldmodels.github.io/",target:"_blank",rel:"noopener noreferrer"},k={href:"https://www.bilibili.com/read/cv34465959/",target:"_blank",rel:"noopener noreferrer"},D={href:"https://blog.csdn.net/CV_Autobot/article/details/134002647",target:"_blank",rel:"noopener noreferrer"},A=e("h3",{id:"_2-è®ºæ–‡ç»¼è¿°",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-è®ºæ–‡ç»¼è¿°"},[e("span",null,"2.è®ºæ–‡ç»¼è¿°")])],-1),y=e("strong",null,[e("code",null,"arxiv")],-1),x={href:"https://arxiv.org/abs/2403.02622",target:"_blank",rel:"noopener noreferrer"},M={href:"https://arxiv.org/abs/2403.02622",target:"_blank",rel:"noopener noreferrer"},W=e("strong",null,[e("code",null,"arxiv")],-1),P={href:"https://arxiv.org/pdf/2401.12888.pdf",target:"_blank",rel:"noopener noreferrer"},I=e("strong",null,[e("code",null,"arxiv")],-1),S={href:"https://arxiv.org/pdf/2401.08045.pdf",target:"_blank",rel:"noopener noreferrer"},C=e("h2",{id:"_3-æŒ‘æˆ˜èµ›-workshops-challenges",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_3-æŒ‘æˆ˜èµ›-workshops-challenges"},[e("span",null,"3.æŒ‘æˆ˜èµ› Workshops/Challenges")])],-1),T=e("strong",null,[e("code",null,"Challenges")],-1),L={href:"https://github.com/1x-technologies/1xgpt",target:"_blank",rel:"noopener noreferrer"},V=e("strong",null,[e("code",null,"Challenges")],-1),G={href:"https://opendrivelab.com/challenge2024/",target:"_blank",rel:"noopener noreferrer"},E=e("h2",{id:"tutorials-talks",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#tutorials-talks"},[e("span",null,"Tutorials/Talks/")])],-1),R=e("strong",null,[e("code",null,"from Wayve")],-1),N={href:"https://www.youtube.com/watch?v=lNOs08byOhw",target:"_blank",rel:"noopener noreferrer"},O={href:"https://www.youtube.com/watch?v=wMvYjiv6EpY",target:"_blank",rel:"noopener noreferrer"},U=e("h2",{id:"â¢-ä¼˜ç§€å›¢é˜Ÿ-å­¦æœ¯å¤§ä½¬-å…¬å¸",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#â¢-ä¼˜ç§€å›¢é˜Ÿ-å­¦æœ¯å¤§ä½¬-å…¬å¸"},[e("span",null,"â¢ ä¼˜ç§€å›¢é˜Ÿ / å­¦æœ¯å¤§ä½¬/ å…¬å¸")])],-1),z={id:"â– -ä¸Šæµ·ailab-ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤-https-opendrivelab-com-publications",tabindex:"-1"},q={class:"header-anchor",href:"#â– -ä¸Šæµ·ailab-ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤-https-opendrivelab-com-publications"},B={href:"https://opendrivelab.com/publications/",target:"_blank",rel:"noopener noreferrer"},F={id:"â– -é¦™æ¸¯ä¸­æ–‡å¤§å­¦-é™ˆé“ è€å¸ˆå›¢é˜Ÿ-geometric-controllable-visual-generation-a-systematic-solution-video",tabindex:"-1"},K={class:"header-anchor",href:"#â– -é¦™æ¸¯ä¸­æ–‡å¤§å­¦-é™ˆé“ è€å¸ˆå›¢é˜Ÿ-geometric-controllable-visual-generation-a-systematic-solution-video"},j={href:"https://www.bilibili.com/video/BV18T421v7Nf/?spm_id_from=333.337.search-card.all.click",target:"_blank",rel:"noopener noreferrer"},J={id:"â– -æä½³ç§‘æŠ€-æä½³ç§‘æŠ€drivedreamerè‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ã€worlddreameré€šç”¨ä¸–ç•Œæ¨¡å‹ç›®å‰å·²æˆåŠŸå•†ä¸šåŒ–è½åœ°ã€‚-æ¨æ–‡",tabindex:"-1"},H={class:"header-anchor",href:"#â– -æä½³ç§‘æŠ€-æä½³ç§‘æŠ€drivedreamerè‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ã€worlddreameré€šç”¨ä¸–ç•Œæ¨¡å‹ç›®å‰å·²æˆåŠŸå•†ä¸šåŒ–è½åœ°ã€‚-æ¨æ–‡"},X={href:"https://baijiahao.baidu.com/s?id=1799624134723943641",target:"_blank",rel:"noopener noreferrer"},Z=e("h4",{id:"â– -wayveã€teslaã€æ—·è§†ã€ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#â– -wayveã€teslaã€æ—·è§†ã€ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€"},[e("span",null,"â–  Wayveã€Teslaã€æ—·è§†ã€ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€")])],-1),Y={id:"â– -è”šæ¥è½¦ä¼-https-www-qbitai-com-2024-07-172025-html",tabindex:"-1"},Q={class:"header-anchor",href:"#â– -è”šæ¥è½¦ä¼-https-www-qbitai-com-2024-07-172025-html"},$={href:"https://www.qbitai.com/2024/07/172025.html",target:"_blank",rel:"noopener noreferrer"},ee=t('<h2 id="â¢-ç»å…¸è®ºæ–‡-æ¨èåŠ -ğŸ‘" tabindex="-1"><a class="header-anchor" href="#â¢-ç»å…¸è®ºæ–‡-æ¨èåŠ -ğŸ‘"><span>â¢ ç»å…¸è®ºæ–‡ï¼šï¼ˆæ¨èåŠ â€œğŸ‘â€ï¼‰</span></a></h2><h4 id="world-models-are-adept-at-representing-an-agent-s-spatio-temporal-knowledge-about-its-environment-through-the-prediction-of-future-changes" tabindex="-1"><a class="header-anchor" href="#world-models-are-adept-at-representing-an-agent-s-spatio-temporal-knowledge-about-its-environment-through-the-prediction-of-future-changes"><span>World Models are adept at representing an agent&#39;s spatio-temporal knowledge about its environment through the prediction of future changes.</span></a></h4><h4 id="there-are-two-main-types-of-world-models-in-autonomous-driving-aimed-at-reducing-driving-uncertainty-i-e-world-model-as-neural-driving-simulator-and-world-model-for-end-to-end-driving" tabindex="-1"><a class="header-anchor" href="#there-are-two-main-types-of-world-models-in-autonomous-driving-aimed-at-reducing-driving-uncertainty-i-e-world-model-as-neural-driving-simulator-and-world-model-for-end-to-end-driving"><span>There are two main types of world models in Autonomous Driving aimed at reducing driving uncertainty, i.e., World Model as Neural Driving Simulator and World Model for End-to-end Driving.</span></a></h4><h4 id="in-the-real-environment-methods-like-gaia-1-and-copilot4d-involve-utilizing-generative-models-to-construct-neural-simulators-that-produce-2d-or-3d-future-scenes-to-enhance-predictive-capabilities" tabindex="-1"><a class="header-anchor" href="#in-the-real-environment-methods-like-gaia-1-and-copilot4d-involve-utilizing-generative-models-to-construct-neural-simulators-that-produce-2d-or-3d-future-scenes-to-enhance-predictive-capabilities"><span>In the real environment, methods like GAIA-1 and Copilot4D involve utilizing generative models to construct neural simulators that produce 2D or 3D future scenes to enhance predictive capabilities.</span></a></h4><h4 id="in-the-simulation-environment-methods-such-as-mile-and-trafficbots-are-based-on-reinforcement-learning-enhancing-their-capacity-for-decision-making-and-future-prediction-thereby-paving-the-way-to-end-to-end-autonomous-driving" tabindex="-1"><a class="header-anchor" href="#in-the-simulation-environment-methods-such-as-mile-and-trafficbots-are-based-on-reinforcement-learning-enhancing-their-capacity-for-decision-making-and-future-prediction-thereby-paving-the-way-to-end-to-end-autonomous-driving"><span>In the simulation environment, methods such as MILE and TrafficBots are based on reinforcement learning, enhancing their capacity for decision-making and future prediction, thereby paving the way to end-to-end autonomous driving.</span></a></h4><h3 id="neural-driving-simulator-based-on-world-models" tabindex="-1"><a class="header-anchor" href="#neural-driving-simulator-based-on-world-models"><span>Neural Driving Simulator based on World Models</span></a></h3><h4 id="_2d-scene-generation" tabindex="-1"><a class="header-anchor" href="#_2d-scene-generation"><span>2D Scene Generation</span></a></h4>',7),re={href:"https://arxiv.org/abs/2309.17080",target:"_blank",rel:"noopener noreferrer"},oe={href:"https://wayve.ai/thinking/scaling-gaia-1/",target:"_blank",rel:"noopener noreferrer"},ne={href:"https://www.youtube.com/watch?v=6x-Xb_uT7ts",target:"_blank",rel:"noopener noreferrer"},te={href:"https://drivedreamer.github.io/",target:"_blank",rel:"noopener noreferrer"},ae={href:"https://github.com/JeffWang987/DriveDreamer",target:"_blank",rel:"noopener noreferrer"},ie={href:"https://arxiv.org/abs/2311.13549",target:"_blank",rel:"noopener noreferrer"},le={href:"https://arxiv.org/abs/2310.07771",target:"_blank",rel:"noopener noreferrer"},se={href:"https://panacea-ad.github.io/",target:"_blank",rel:"noopener noreferrer"},de={href:"https://github.com/wenyuqing/panacea",target:"_blank",rel:"noopener noreferrer"},he={href:"https://drive-wm.github.io/",target:"_blank",rel:"noopener noreferrer"},ce={href:"https://github.com/BraveGroup/Drive-WM",target:"_blank",rel:"noopener noreferrer"},ue={href:"https://arxiv.org/abs/2312.02934",target:"_blank",rel:"noopener noreferrer"},pe={href:"https://drivedreamer2.github.io/",target:"_blank",rel:"noopener noreferrer"},ge={href:"https://github.com/f1yfisher/DriveDreamer2",target:"_blank",rel:"noopener noreferrer"},me={href:"https://arxiv.org/abs/2403.09630",target:"_blank",rel:"noopener noreferrer"},_e={href:"https://github.com/OpenDriveLab/DriveAGI?tab=readme-ov-file",target:"_blank",rel:"noopener noreferrer"},fe={href:"https://subjectdrive.github.io/",target:"_blank",rel:"noopener noreferrer"},ve=e("h4",{id:"_3d-scene-generation",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_3d-scene-generation"},[e("span",null,"3D Scene Generation")])],-1),be={href:"https://arxiv.org/abs/2311.01017",target:"_blank",rel:"noopener noreferrer"},we={href:"https://arxiv.org/abs/2311.16038",target:"_blank",rel:"noopener noreferrer"},ke={href:"https://github.com/wzzheng/OccWorld",target:"_blank",rel:"noopener noreferrer"},De={href:"https://arxiv.org/abs/2311.11762",target:"_blank",rel:"noopener noreferrer"},Ae={href:"https://www.zyrianov.org/lidardm/",target:"_blank",rel:"noopener noreferrer"},ye={href:"https://github.com/vzyrianov/lidardm",target:"_blank",rel:"noopener noreferrer"},xe=e("h4",{id:"_4d-pre-training-for-autonomous-driving",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_4d-pre-training-for-autonomous-driving"},[e("span",null,"4D Pre-training for Autonomous Driving")])],-1),Me={href:"https://arxiv.org/abs/2308.07234",target:"_blank",rel:"noopener noreferrer"},We={href:"https://arxiv.org/abs/2312.17655",target:"_blank",rel:"noopener noreferrer"},Pe={href:"https://github.com/OpenDriveLab/ViDAR",target:"_blank",rel:"noopener noreferrer"},Ie=e("li",null,[r("ğŸ‘(2024 CVPR) DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving ["),e("a",{href:"XXX"},"Paper"),r("] (PKU)")],-1),Se=e("h3",{id:"end-to-end-driving-based-on-world-models",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#end-to-end-driving-based-on-world-models"},[e("span",null,"End-to-end Driving based on World Models")])],-1),Ce={href:"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9316769afaaeeaad42a9e3633b14e801-Abstract-Conference.html",target:"_blank",rel:"noopener noreferrer"},Te={href:"https://proceedings.neurips.cc/paper_files/paper/2022/hash/827cb489449ea216e4a257c47e407d18-Abstract-Conference.html",target:"_blank",rel:"noopener noreferrer"},Le={href:"https://github.com/wayveai/mile",target:"_blank",rel:"noopener noreferrer"},Ve={href:"https://arxiv.org/abs/2210.04017",target:"_blank",rel:"noopener noreferrer"},Ge={href:"https://ieeexplore.ieee.org/abstract/document/10161243",target:"_blank",rel:"noopener noreferrer"},Ee={href:"https://arxiv.org/abs/2402.16720",target:"_blank",rel:"noopener noreferrer"},Re=e("h3",{id:"others",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#others"},[e("span",null,"Others")])],-1),Ne={href:"http://www.sci.brooklyn.cuny.edu/~parsons/courses/3415-fall-2011/papers/elfes.pdf",target:"_blank",rel:"noopener noreferrer"},Oe=e("h2",{id:"â¢-ç»å…¸é¡¹ç›®",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#â¢-ç»å…¸é¡¹ç›®"},[e("span",null,"â¢ ç»å…¸é¡¹ç›®")])],-1),Ue={href:"https://github.com/cvlab-yonsei/MNAD",target:"_blank",rel:"noopener noreferrer"},ze=t('<h2 id="â¢-å‘ç°çš„æ–°çš„æœ‰æ„æ€çš„ç ”ç©¶æ–¹å‘" tabindex="-1"><a class="header-anchor" href="#â¢-å‘ç°çš„æ–°çš„æœ‰æ„æ€çš„ç ”ç©¶æ–¹å‘"><span>â¢ å‘ç°çš„æ–°çš„æœ‰æ„æ€çš„ç ”ç©¶æ–¹å‘--&gt;</span></a></h2><p>ç”Ÿæˆå¼çš„World Modelå¯ä»¥è¢«ç”¨æ¥å½“ä½œä¸€ç§ä»¿çœŸå·¥å…·æ¥ç”Ÿæˆä»¿çœŸæ•°æ®ï¼Œç‰¹åˆ«æ˜¯æä¸ºå°‘è§çš„Corner Caseçš„æ•°æ®ã€‚ ç„¶è€ŒWorld Modelæ›´æœ‰æ½œåŠ›çš„åº”ç”¨æ–¹å‘æ˜¯World Modelå¯èƒ½ä¼šæˆä¸ºåƒGPTä¸€æ ·çš„è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åŸºç¡€æ¨¡å‹ï¼Œè€Œå…¶ä»–è‡ªåŠ¨é©¾é©¶å…·ä½“ä»»åŠ¡éƒ½ä¼šå›´ç»•è¿™ä¸ªåŸºç¡€æ¨¡å‹è¿›è¡Œç ”å‘æ„å»ºã€‚</p><h3 id="_1-definition" tabindex="-1"><a class="header-anchor" href="#_1-definition"><span>1. DEFINITION</span></a></h3><p>The aim of this TASK is to detect and automatically generate high-level explanations of anomalous events in video. Understanding the cause of an anomalous event is crucialas the required response is dependant on its nature andseverity. --&gt; Anomaly Detection &amp; Anoamly Explanation</p><h3 id="_2-related-work" tabindex="-1"><a class="header-anchor" href="#_2-related-work"><span>2. RELATED WORK</span></a></h3><p>[1] Joint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge (ICCV 2017)<br> [2] X-MAN: Explaining multiple sources of anomalies in video (CVPR workshop 2021)<br> [3] Discrete neural representations for explainable anomaly detection (WACV 2022)</p>',6);function qe(Be,Fe){const o=i("ExternalLinkIcon");return l(),s("div",null,[h,e("p",null,[r("[1] "),e("a",c,[r("https://github.com/GigaAI-research/General-World-Models-Survey"),n(o)]),r(" è¯¥ repo å†…æœ‰ç›®å‰ä¸–ç•Œæ¨¡å‹æ–¹å‘çš„ä¼˜ç§€è®ºæ–‡æ±‡æ€»ï¼ŒåŒ…æ‹¬åŸºæœ¬åˆ†ç±»ï¼šè§†é¢‘ç”Ÿæˆã€è‡ªåŠ¨é©¾é©¶å’Œè‡ªä¸»ä»£ç†ã€‚å…¶ä¸­è‡ªåŠ¨é©¾é©¶åˆ†æˆç«¯åˆ°ç«¯ã€ä»¥åŠ2Dã€3Dç¥ç»æ¨¡æ‹Ÿå™¨æ–¹æ³•ã€‚ä¸–ç•Œæ¨¡å‹çš„æ–‡çŒ®ã€ å¼€æºcodeã€ ç»¼è¿°ã€‚")]),e("p",null,[r("[2] "),e("a",u,[r("https://github.com/HaoranZhuExplorer/World-Models-Autonomous-Driving-Latest-Survey"),n(o)]),r(" è¯¥repo å†…ä»¥â€˜æ—¶é—´â€™ä¸ºé¡ºåºç²¾é€‰ç›¸å…³ä¸–ç•Œè‡ªåŠ¨é©¾é©¶æ¨¡å‹ã€‚ä¸”å¹¶æŒç»­æ›´æ–°ï¼ŒåŒ…æ‹¬ä¸€äº›æŒ‘æˆ˜ã€ç›¸å…³è§†é¢‘ï¼ŒåŒ…æ‹¬æœºå™¨äººé¢†åŸŸçš„ä¸–ç•Œæ¨¡å‹ä½¿ç”¨ï¼ˆå¤§å¤šæ•°ä¸ºæ¨¡ä»¿å­¦ä¹ å¼ºåŒ–å­¦ä¹ æ–¹å‘ï¼‰å¯å‚è€ƒå€Ÿé‰´ã€‚")]),e("p",null,[r("[3] "),e("a",p,[r("Awesome-World-Models-for-AD "),n(o)])]),e("p",null,[r("[4] "),e("a",g,[r("World models paper list from Shanghai AI lab"),n(o)])]),e("p",null,[r("[5] "),e("a",m,[r("Awesome-Papers-World-Models-Autonomous-Driving"),n(o)]),r(".")]),_,f,e("p",null,[r("[1] ä¸–ç•Œæ¨¡å‹ç®€ä»‹ï¼š"),e("a",v,[r("https://mp.weixin.qq.com/s/UmT0DjFqRPsjv2m28ySvdw"),n(o)]),r("ä¸–ç•Œæ¨¡å‹æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆå¤šç§æ„ŸçŸ¥ä¿¡æ¯ï¼Œå¦‚è§†è§‰ã€å¬è§‰å’Œè¯­è¨€ï¼Œåˆ©ç”¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç­‰æ–¹æ³•æ¥ç†è§£å’Œé¢„æµ‹ç°å®ä¸–ç•Œã€‚å®ƒåŒ…æ‹¬æ„ŸçŸ¥æ¨¡å—ã€è¡¨å¾å­¦ä¹ ã€åŠ¨åŠ›å­¦æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºæ„å»ºç¯å¢ƒçš„å†…éƒ¨è¡¨ç¤ºï¼Œä¸ä»…èƒ½åæ˜ å½“å‰çŠ¶æ€ï¼Œè¿˜èƒ½é¢„æµ‹æœªæ¥å˜åŒ–ã€‚è¿™ç§æ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆå¼€å‘å’Œæœºå™¨äººå­¦ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚Yann LeCunæå‡ºçš„è¿™ä¸€æ¦‚å¿µï¼Œå¼ºè°ƒé€šè¿‡è‡ªç›‘ç£å­¦ä¹ è®©AIåƒäººä¸€æ ·ç†è§£ä¸–ç•Œï¼Œå½¢æˆå†…éƒ¨çš„å¿ƒç†è¡¨å¾ï¼Œä»¥æœŸå®ç°é€šç”¨äººå·¥æ™ºèƒ½ã€‚Metaçš„I-JEPAæ¨¡å‹æ˜¯åŸºäºè¿™ä¸€æ„¿æ™¯çš„å®ç°ï¼Œå®ƒé€šè¿‡åˆ†æå’Œè¡¥å…¨å›¾åƒå±•ç¤ºäº†å¯¹ä¸–ç•ŒèƒŒæ™¯çŸ¥è¯†çš„åº”ç”¨ã€‚")]),e("p",null,[r("[2] å½±å“è¾ƒå¤§çš„æ—©æœŸä¸–ç•Œæ¨¡å‹æ–‡ç« ï¼š2018å¹´Jurgenåœ¨NeurIPS ä»¥å¾ªç¯ä¸–ç•Œæ¨¡å‹ä¿ƒè¿›ç­–ç•¥æ¼”å˜â€œRecurrent World Models Facilitate Policy Evolutionâ€çš„titleå‘è¡¨ï¼šé“¾æ¥: "),e("a",b,[r("https://arxiv.org/abs/1803.10122"),n(o)]),r(" ç¤ºä¾‹: "),e("a",w,[r("https://worldmodels.github.io/"),n(o)])]),e("p",null,[r("[3] ä¸–ç•Œæ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åº”ç”¨ï¼š "),e("a",k,[r("https://www.bilibili.com/read/cv34465959/"),n(o)])]),e("p",null,[r("[4] ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆä»¥åŠä»¿çœŸå¹³å°: "),e("a",D,[r("https://blog.csdn.net/CV_Autobot/article/details/134002647"),n(o)])]),A,e("p",null,[r("[1] 2024-Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyondï¼Œ "),y,r(),e("a",x,[r("Paper"),n(o)]),r(" æä½³ç§‘æŠ€ ï¼ˆæ¯”è¾ƒå…¨é¢ï¼Œè¯¥ç»¼è¿°é€šè¿‡ 260 ä½™ç¯‡æ–‡çŒ®ï¼Œå¯¹ä¸–ç•Œæ¨¡å‹åœ¨è§†é¢‘ç”Ÿæˆã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ä½“ã€é€šç”¨æœºå™¨äººç­‰é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨è¿›è¡Œäº†è¯¦å°½çš„åˆ†æå’Œè®¨è®ºã€‚å¦å¤–ï¼Œè¯¥ç»¼è¿°è¿˜å®¡è§†äº†å½“å‰ä¸–ç•Œæ¨¡å‹çš„æŒ‘æˆ˜å’Œå±€é™æ€§ï¼Œå¹¶å±•æœ›äº†å®ƒä»¬æœªæ¥çš„å‘å±•æ–¹å‘ã€‚ï¼‰")]),e("p",null,[r("[2] 2024-World Models for Autonomous Driving: An Initial Surveyï¼ŒIEEE TIV,æ¾³é—¨å¤§å­¦ï¼Œå¤å¨å¤·å¤§å­¦ã€‚"),e("a",M,[r("Paper"),n(o)]),r("ï¼ˆç”»é£æœ‰è¶£ï¼Œå¯¹è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹çš„ç°çŠ¶å’Œæœªæ¥è¿›å±•è¿›è¡Œäº†åˆæ­¥å›é¡¾ï¼Œæ¶µç›–äº†å®ƒä»¬çš„ç†è®ºåŸºç¡€ã€å®é™…åº”ç”¨ä»¥åŠæ—¨åœ¨å…‹æœç°æœ‰å±€é™æ€§çš„æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶å·¥ä½œã€‚ï¼‰")]),e("p",null,[r("[3]2024-Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies "),W,r(),e("a",P,[r("Paper"),n(o)])]),e("p",null,[r("[4]2024-Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities "),I,r(),e("a",S,[r("Paper"),n(o)])]),C,e("ul",null,[e("li",null,[e("p",null,[r("2024-1X World Model Challenge "),T,r(),e("a",L,[r("Link"),n(o)])])]),e("li",null,[e("p",null,[r("2024-CVPR Workshop, Foundation Models for Autonomous Systems, Challenges, Track 4: Predictive World Model "),V,r(),e("a",G,[r("Link"),n(o)])])])]),E,e("ul",null,[e("li",null,[e("p",null,[r("2023 "),R,r("; "),e("a",N,[r("Video"),n(o)])])]),e("li",null,[e("p",null,[r("2022-Neural World Models for Autonomous Driving "),e("a",O,[r("Video"),n(o)])])])]),U,e("h4",z,[e("a",q,[e("span",null,[r("â–  ä¸Šæµ·AILabï¼ˆä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ï¼‰ "),e("a",B,[r("https://opendrivelab.com/publications/"),n(o)])])])]),e("h4",F,[e("a",K,[e("span",null,[r("â–  é¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆé™ˆé“ è€å¸ˆå›¢é˜Ÿï¼‰Geometric-Controllable Visual Generation: A Systematic Solution "),e("a",j,[r("Video"),n(o)])])])]),e("h4",J,[e("a",H,[e("span",null,[r("â–  æä½³ç§‘æŠ€ï¼ˆæä½³ç§‘æŠ€DriveDreamerè‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ã€WorldDreameré€šç”¨ä¸–ç•Œæ¨¡å‹ç›®å‰å·²æˆåŠŸå•†ä¸šåŒ–è½åœ°ã€‚ï¼‰"),e("a",X,[r("æ¨æ–‡"),n(o)])])])]),Z,e("h4",Y,[e("a",Q,[e("span",null,[r("â–  è”šæ¥è½¦ä¼ï¼š"),e("a",$,[r("https://www.qbitai.com/2024/07/172025.html"),n(o)])])])]),ee,e("ul",null,[e("li",null,[r("ğŸ‘(2023 Arxiv) GAIA-1: A generative world model for autonomous driving ["),e("a",re,[r("Paper"),n(o)]),r("]["),e("a",oe,[r("Blog"),n(o)]),r("] (Wayve)")]),e("li",null,[r("(2023 CVPR 2023 workshop) ["),e("a",ne,[r("Video"),n(o)]),r("] (Tesla)")]),e("li",null,[r("ğŸ‘(2023 Arxiv) DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving ["),e("a",te,[r("Paper"),n(o)]),r("]["),e("a",ae,[r("Code"),n(o)]),r("] (GigaAI)")]),e("li",null,[r("(2023 Arxiv) ADriver-I: A General World Model for Autonomous Driving ["),e("a",ie,[r("Paper"),n(o)]),r("] (MEGVII)")]),e("li",null,[r("ğŸ‘(2023 Arxiv) DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model ["),e("a",le,[r("Paper"),n(o)]),r("] (Baidu)")]),e("li",null,[r("(2023 Arxiv) Panacea: Panoramic and Controllable Video Generation for Autonomous Driving ["),e("a",se,[r("Paper"),n(o)]),r("]["),e("a",de,[r("Code"),n(o)]),r("] (MEGVII)")]),e("li",null,[r("ğŸ‘(2024 CVPR) Drive-WM: Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving ["),e("a",he,[r("Paper"),n(o)]),r("]["),e("a",ce,[r("Code"),n(o)]),r("] (CASIA)")]),e("li",null,[r("(2023 Arxiv) WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera Driving Scene Generation ["),e("a",ue,[r("Paper"),n(o)]),r("] (Fudan)")]),e("li",null,[r("(2024 Arxiv) DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation ["),e("a",pe,[r("Paper"),n(o)]),r("]["),e("a",ge,[r("Code"),n(o)]),r("] (GigaAI)")]),e("li",null,[r("(2024 CVPR) GenAD: Generalized Predictive Model for Autonomous Driving ["),e("a",me,[r("Paper"),n(o)]),r("]["),e("a",_e,[r("Code"),n(o)]),r("] (Shanghai AI Lab)")]),e("li",null,[r("(2024 Arxiv) SubjectDrive: Scaling Generative Data in Autonomous Driving via Subject Control ["),e("a",fe,[r("Paper"),n(o)]),r("] (MEGVII)")])]),ve,e("ul",null,[e("li",null,[r("ğŸ‘(2024 ICLR) Copilot4D:Learning unsupervised world models for autonomous driving via discrete diffusion ["),e("a",be,[r("Paper"),n(o)]),r("] (Waabi)")]),e("li",null,[r("(2023 Arxiv) OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving ["),e("a",we,[r("Paper"),n(o)]),r("]["),e("a",ke,[r("Code"),n(o)]),r("] (THU)")]),e("li",null,[r("(2023 Arxiv) MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations ["),e("a",De,[r("Paper"),n(o)]),r("] (KIT)")]),e("li",null,[r("(2024 Arxiv) LidarDM: Generative LiDAR Simulation in a Generated World ["),e("a",Ae,[r("Paper"),n(o)]),r("]["),e("a",ye,[r("Code"),n(o)]),r("] (MIT)")])]),xe,e("ul",null,[e("li",null,[r("(2023 Arxiv) UniWorld: Autonomous Driving Pre-training via World Models ["),e("a",Me,[r("Paper"),n(o)]),r("] (PKU)")]),e("li",null,[r("(2024 CVPR) ViDAR: Visual Point Cloud Forecasting enables Scalable Autonomous Driving ["),e("a",We,[r("Paper"),n(o)]),r("]["),e("a",Pe,[r("Code"),n(o)]),r("] (Shanghai AI Lab)")]),Ie]),Se,e("ul",null,[e("li",null,[r("ğŸ‘(2022 NeurIPS) Iso-Dream: Isolating and Leveraging Noncontrollable Visual Dynamics in World Models ["),e("a",Ce,[r("Paper"),n(o)]),r("] (SJTU)")]),e("li",null,[r("ğŸ‘(2022 NeurIPS) MILE: Model-Based Imitation Learning for Urban Driving ["),e("a",Te,[r("Paper"),n(o)]),r("]["),e("a",Le,[r("Code"),n(o)]),r("] (Wayve)")]),e("li",null,[r("(2022 NeurIPS Deep RL Workshop) SEM2: Enhance Sample Efficiency and Robustness of End-to-end Urban Autonomous Driving via Semantic Masked World Model ["),e("a",Ve,[r("Paper"),n(o)]),r("] (HIT & THU)")]),e("li",null,[r("(2023 ICRA) TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction ["),e("a",Ge,[r("Paper"),n(o)]),r("] (ETH Zurich)")]),e("li",null,[r("(2024 Arxiv) Think2Drive: Efficient Reinforcement Learning by Thinking in Latent World Model for Quasi-Realistic Autonomous Driving (in CARLA-v2) ["),e("a",Ee,[r("Paper"),n(o)]),r("] (SJTU)")])]),Re,e("ul",null,[e("li",null,[r("(1989) Using Occupancy Grids for Mobile Robot Perception and Navigation ["),e("a",Ne,[r("paper"),n(o)]),r("]")])]),Oe,e("p",null,[r("â—‹ MNAD --> "),e("a",Ue,[r("https://github.com/cvlab-yonsei/MNAD"),n(o)]),r(" å¯ä½œä¸ºbaseline.")]),ze])}const Je=a(d,[["render",qe],["__file","generation.html.vue"]]),He=JSON.parse('{"path":"/worldmodel/generation.html","title":"World-Models-Autonomous-Driving-Latest-Survey","lang":"en-US","frontmatter":{"description":"World-Models-Autonomous-Driving-Latest-Survey A curated list of world model for autonmous driving. Keep updated. ğŸ“Œ Introduction âœ§ ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç† â¢ è®ºæ–‡æ±‡æ€» [1] https://github...","head":[["meta",{"property":"og:url","content":"https://openvisuallab.github.io/worldmodel/generation.html"}],["meta",{"property":"og:site_name","content":"OpenVisualLab"}],["meta",{"property":"og:title","content":"World-Models-Autonomous-Driving-Latest-Survey"}],["meta",{"property":"og:description","content":"World-Models-Autonomous-Driving-Latest-Survey A curated list of world model for autonmous driving. Keep updated. ğŸ“Œ Introduction âœ§ ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç† â¢ è®ºæ–‡æ±‡æ€» [1] https://github..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-09-13T02:40:58.000Z"}],["meta",{"property":"article:author","content":"OpenVisualLab"}],["meta",{"property":"article:modified_time","content":"2024-09-13T02:40:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"World-Models-Autonomous-Driving-Latest-Survey\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-09-13T02:40:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OpenVisualLab\\",\\"url\\":\\"https://openvisuallab.github.io\\"}]}"]]},"headers":[{"level":2,"title":"ğŸ“Œ Introduction","slug":"ğŸ“Œ-introduction","link":"#ğŸ“Œ-introduction","children":[]},{"level":2,"title":"âœ§ ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†","slug":"âœ§-ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†","link":"#âœ§-ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†","children":[]},{"level":2,"title":"â¢ è®ºæ–‡æ±‡æ€»","slug":"â¢-è®ºæ–‡æ±‡æ€»","link":"#â¢-è®ºæ–‡æ±‡æ€»","children":[]},{"level":2,"title":"â¢ è®¤è¯†ä¸–ç•Œæ¨¡å‹","slug":"â¢-è®¤è¯†ä¸–ç•Œæ¨¡å‹","link":"#â¢-è®¤è¯†ä¸–ç•Œæ¨¡å‹","children":[{"level":3,"title":"1. ç®€å•ä»‹ç»ï¼ˆä»ä¸–ç•Œæ¨¡å‹--> è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ç”¨äºåœºæ™¯ç”Ÿæˆï¼‰","slug":"_1-ç®€å•ä»‹ç»-ä»ä¸–ç•Œæ¨¡å‹-è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ç”¨äºåœºæ™¯ç”Ÿæˆ","link":"#_1-ç®€å•ä»‹ç»-ä»ä¸–ç•Œæ¨¡å‹-è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡å‹ç”¨äºåœºæ™¯ç”Ÿæˆ","children":[]},{"level":3,"title":"2.è®ºæ–‡ç»¼è¿°","slug":"_2-è®ºæ–‡ç»¼è¿°","link":"#_2-è®ºæ–‡ç»¼è¿°","children":[]}]},{"level":2,"title":"3.æŒ‘æˆ˜èµ› Workshops/Challenges","slug":"_3-æŒ‘æˆ˜èµ›-workshops-challenges","link":"#_3-æŒ‘æˆ˜èµ›-workshops-challenges","children":[]},{"level":2,"title":"Tutorials/Talks/","slug":"tutorials-talks","link":"#tutorials-talks","children":[]},{"level":2,"title":"â¢ ä¼˜ç§€å›¢é˜Ÿ / å­¦æœ¯å¤§ä½¬/ å…¬å¸","slug":"â¢-ä¼˜ç§€å›¢é˜Ÿ-å­¦æœ¯å¤§ä½¬-å…¬å¸","link":"#â¢-ä¼˜ç§€å›¢é˜Ÿ-å­¦æœ¯å¤§ä½¬-å…¬å¸","children":[]},{"level":2,"title":"â¢ ç»å…¸è®ºæ–‡ï¼šï¼ˆæ¨èåŠ â€œğŸ‘â€ï¼‰","slug":"â¢-ç»å…¸è®ºæ–‡-æ¨èåŠ -ğŸ‘","link":"#â¢-ç»å…¸è®ºæ–‡-æ¨èåŠ -ğŸ‘","children":[{"level":3,"title":"Neural Driving Simulator based on World Models","slug":"neural-driving-simulator-based-on-world-models","link":"#neural-driving-simulator-based-on-world-models","children":[]},{"level":3,"title":"End-to-end Driving based on World Models","slug":"end-to-end-driving-based-on-world-models","link":"#end-to-end-driving-based-on-world-models","children":[]},{"level":3,"title":"Others","slug":"others","link":"#others","children":[]}]},{"level":2,"title":"â¢ ç»å…¸é¡¹ç›®","slug":"â¢-ç»å…¸é¡¹ç›®","link":"#â¢-ç»å…¸é¡¹ç›®","children":[]},{"level":2,"title":"â¢ å‘ç°çš„æ–°çš„æœ‰æ„æ€çš„ç ”ç©¶æ–¹å‘-->","slug":"â¢-å‘ç°çš„æ–°çš„æœ‰æ„æ€çš„ç ”ç©¶æ–¹å‘","link":"#â¢-å‘ç°çš„æ–°çš„æœ‰æ„æ€çš„ç ”ç©¶æ–¹å‘","children":[{"level":3,"title":"1. DEFINITION","slug":"_1-definition","link":"#_1-definition","children":[]},{"level":3,"title":"2. RELATED WORK","slug":"_2-related-work","link":"#_2-related-work","children":[]}]}],"git":{"createdTime":1726102486000,"updatedTime":1726195258000,"contributors":[{"name":"mingzhuzhang1","email":"145547769+mingzhuzhang1@users.noreply.github.com","commits":2}]},"readingTime":{"minutes":6.18,"words":1853},"filePathRelative":"worldmodel/generation.md","localizedDate":"September 12, 2024","excerpt":"\\n<p>A curated list of world model for autonmous driving. Keep updated.</p>\\n<h2>ğŸ“Œ Introduction</h2>\\n<h2>âœ§ ä¸–ç•Œæ¨¡å‹ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ç”Ÿæˆç›¸å…³æ–‡çŒ®æ•´ç†</h2>\\n<h2>â¢ è®ºæ–‡æ±‡æ€»</h2>\\n<p>[1] <a href=\\"https://github.com/GigaAI-research/General-World-Models-Survey\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://github.com/GigaAI-research/General-World-Models-Survey</a> è¯¥ repo å†…æœ‰ç›®å‰ä¸–ç•Œæ¨¡å‹æ–¹å‘çš„ä¼˜ç§€è®ºæ–‡æ±‡æ€»ï¼ŒåŒ…æ‹¬åŸºæœ¬åˆ†ç±»ï¼šè§†é¢‘ç”Ÿæˆã€è‡ªåŠ¨é©¾é©¶å’Œè‡ªä¸»ä»£ç†ã€‚å…¶ä¸­è‡ªåŠ¨é©¾é©¶åˆ†æˆç«¯åˆ°ç«¯ã€ä»¥åŠ2Dã€3Dç¥ç»æ¨¡æ‹Ÿå™¨æ–¹æ³•ã€‚ä¸–ç•Œæ¨¡å‹çš„æ–‡çŒ®ã€ å¼€æºcodeã€ ç»¼è¿°ã€‚</p>","autoDesc":true}');export{Je as comp,He as data};
