---
title: DriveLM (Wang Jingxin)
order: 2
---

DriveLM: Driving with Graph Visual Question Answering

分享人: Wang Jingxin (王京新) 

## 收获总结

1、
2、
3、


## 分享摘要



[腾讯会议链接](https://meeting.tencent.com/crm/Knap5rOlcf) [论文本地连接](/tinyweekly/papers/DriveLM_ECCV24_driving_with_language.pdf) 

[[paper]](https://eccv.ecva.net/virtual/2024/poster/130) [[github🌟870]](https://github.com/OpenDriveLab/DriveLM) [[project page]](https://opendrivelab.com/DriveLM/)
[CVPR Workshop Challenge](https://opendrivelab.com/challenge2024/#driving_with_language)




分享摘要：</br>
本篇论文针对将通用视觉-语言模型（VLMs）应用于端到端自动驾驶中的挑战；受到1、大规模预训练的视觉-语言模型在多任务中的通用性和推理能力；2、人类驾驶员会分多个步骤对决策进行推理的启发；提出了DriveLM，一个结合语言输入的自动驾驶框架，包括DriveLM-nuScenes和DriveLM-CARLA两个数据集，任务定义涵盖感知、预测、规划三个阶段，以及相关的评估方法；提升了VLMs 在自动驾驶场景中的适应性和推理能力，尤其是在处理未见场景和传感器配置方面，达到了与专用驾驶模型相媲美甚至超越的表现的效果，验证了语言驱动驾驶的潜力。


## 问答简记

$Q:$

$A:$

---

$Q:$

$A:$

---

$Q:$

$A:$


## 相关论文

